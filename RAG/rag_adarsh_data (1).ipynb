{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain\n",
    "! pip install langchain langchain_community\n",
    "!pip install -q langchain\n",
    "!pip install -q torch\n",
    "!pip install -q transformers\n",
    "!pip install -q sentence-transformers\n",
    "!pip install -q datasets\n",
    "!pip install -q faiss-cpu\n",
    "! pip install CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adarsh.a.kumar.gupta\\OneDrive - Accenture\\Desktop\\accenture\\rag\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import HuggingFaceDatasetLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'adarsh_data_for _rag.txt'}, page_content='[\"hi i am adarsh and i live  in india. \",\\n\"I lives in banglore \",\\n\"i work for a company with my seniors .\",\\n\"my team is like nikil is my yeam lead, anita is reporting to nikhil and  nikhil reports to gautam\",\\n\"i have more firends like arun , aman , atul and jayesh i my team. \",\\n\"from other team i have friednds like akash abhi anvith. anvith is very jolly person supporting abhi too.\",\\n\"akash like doing body building\",\\n\"one of my frind more mentor is prithvi bhaiya, he always supports me and guide me on mistakes. \",\\n\"dileswar and other team leads also help me to learn a lot.\",\\n\\n\"from testing team i have friends lime chandraika , vana and saisudha. sai sudha is also very jolly girl, \",\\n\"she alsways smile even in pressure\",\\n\"people call my team as ai-ml team. i am very happy to join this team under leadership of my team lead cum main boss mr.nikhil.\",\\n\"thank you.\"]')]\n"
     ]
    }
   ],
   "source": [
    "text_data_path=r\"adarsh_data_for _rag.txt\"\n",
    "loader=TextLoader(text_data_path)\n",
    "data=loader.load()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 581, which is longer than the specified 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'adarsh_data_for _rag.txt'}, page_content='[\"hi i am adarsh and i live  in india. \",\\n\"I lives in banglore \",\\n\"i work for a company with my seniors .\",\\n\"my team is like nikil is my yeam lead, anita is reporting to nikhil and  nikhil reports to gautam\",\\n\"i have more firends like arun , aman , atul and jayesh i my team. \",\\n\"from other team i have friednds like akash abhi anvith. anvith is very jolly person supporting abhi too.\",\\n\"akash like doing body building\",\\n\"one of my frind more mentor is prithvi bhaiya, he always supports me and guide me on mistakes. \",\\n\"dileswar and other team leads also help me to learn a lot.\",'),\n",
       " Document(metadata={'source': 'adarsh_data_for _rag.txt'}, page_content='\"from testing team i have friends lime chandraika , vana and saisudha. sai sudha is also very jolly girl, \",\\n\"she alsways smile even in pressure\",\\n\"people call my team as ai-ml team. i am very happy to join this team under leadership of my team lead cum main boss mr.nikhil.\",\\n\"thank you.\"]')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text spliteer: charcters\n",
    "# if  white sapce is coming then, tehn it will take pahele tak  ka text, white space ke baad ka text chor dena bro\n",
    "# take one doc and split it, unrealted with other doc, other doc ka splitting freshly start hoga\n",
    "text_splitter=CharacterTextSplitter(chunk_size=20, chunk_overlap=10)\n",
    "\n",
    "# 'data' holds the text you want to split, split the text into documents using the text splitter.\n",
    "docs = text_splitter.split_documents(data)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adarsh.a.kumar.gupta\\OneDrive - Accenture\\Desktop\\accenture\\rag\\.venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.03833853825926781, 0.12346469610929489, -0.02864299900829792]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vect: token(num form); embedding: token/word/sentence in num form\n",
    "# Define the path to the pre-trained model you want to use\n",
    "modelPath = \"sentence-transformers/all-MiniLM-l6-v2\"\n",
    "\n",
    "# Create a dictionary with model configuration options, specifying to use the CPU for computations\n",
    "model_kwargs = {'device':'cpu'}\n",
    "\n",
    "# Create a dictionary with encoding options, specifically setting 'normalize_embeddings' to False\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "\n",
    "# Initialize an instance of HuggingFaceEmbeddings with the specified parameters\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=modelPath,     # Provide the pre-trained model's path\n",
    "    model_kwargs=model_kwargs, # Pass the model configuration options\n",
    "    encode_kwargs=encode_kwargs # Pass the encoding options\n",
    "    )\n",
    "text = \"This is a test document.\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "query_result[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adarsh.a.kumar.gupta\\OneDrive - Accenture\\Desktop\\accenture\\rag\\.venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEndpoint`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "# Define the repo ID and connect to Mixtral model on Huggingface\n",
    "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "llm = HuggingFaceHub(\n",
    "  repo_id=repo_id, \n",
    "  model_kwargs={\"temperature\": 0.8, \"top_k\": 50}, \n",
    "  huggingfacehub_api_token=\"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\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi i am adarsh and i live  in india. \n",
      "I lives in banglore \n",
      "i work for a company with my seniors .\n",
      "my team is like nikil is my yeam lead, anita is reporting to nikhil and  nikhil reports to gautam\n",
      "i have more firends like arun , aman , atul and jayesh i my team. from other team i have friednds like akash abhi anvith. anvith is very jolly person supporting abhi too.\n"
     ]
    }
   ],
   "source": [
    "# saving data in facebook ai semantic search\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "docs = retriever.get_relevant_documents(\"Who is adarsh?\")\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou are an ai bot. you will be given a question in using context. now you have to use that context and answer for given question.\\n\\nContext: people call my team as ai-ml team. i am very happy to join this team under leadership of my team lead cum main boss mr.nikhil.\\nQuestion: who is nikhil the don\\nAnswer: \\n\\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt enginerring\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are an ai bot. you will be given a question in using context. now you have to use that context and answer for given question.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer: \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template, \n",
    "    input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "\n",
    "question=\"who is nikhil the don\"\n",
    "retriever = db.as_retriever()\n",
    "docs = retriever.get_relevant_documents(question)[0].page_content\n",
    "\n",
    "prompt.format(context=docs,question=question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- \n",
      "You are an ai bot. you will be given a question in using context. now you have to use that context and answer for given question.\n",
      "\n",
      "Context: hi i am adarsh and i live  in india. \n",
      "I lives in banglore \n",
      "i work for a company with my seniors .\n",
      "my team is like nikil is my yeam lead, anita is reporting to nikhil and  nikhil reports to gautam\n",
      "i have more firends like arun , aman , atul and jayesh i my team. from other team i have friednds like akash abhi anvith. anvith is very jolly person supporting abhi too.\n",
      "Question: who is gautam\n",
      "Answer: \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gautam has more firends like arun, aman, atul and jayesh i my team. akash abhi anvith is very jolly person supporting abhi too.'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "question=\"who is gautam\"\n",
    "\n",
    "docs =retriever.get_relevant_documents(question)[0].page_content\n",
    "prompt_main=prompt.format(context=docs,question=question)\n",
    "print(\"---\",prompt_main)\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model_name = 't5-small'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "def summarize(text):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "summarize(prompt_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-1.9007,  2.1180]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of hugging face model loading\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "text = \"I love programming!\"\n",
    "tokens = tokenizer(prompt_main, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access_token_vscode=\"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\"\n",
    "# read_vscode_token=\"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\"\n",
    "\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "\n",
    "# prompt = \"My favorite condiment is\"\n",
    "# model_inputs = tokenizer([prompt], return_tensors=\"pt\")\n",
    "# generated_ids = model.generate(**model_inputs, max_new_tokens=100, do_sample=True)\n",
    "# generated_text = tokenizer.batch_decode(generated_ids)[0]\n",
    "# print(\"Generated text:\", generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an expert data scientist with an expertise in building deep learning models. \n",
      "Explain the concept of asdf in a couple of lines\n",
      "\n",
      "Human:  our input is :2+2\n",
      "AI:  final output is :4\n",
      "Human:  our input is :2+3\n",
      "AI:  final output is :5\n"
     ]
    }
   ],
   "source": [
    "# Import prompt and define PromptTemplate\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are an expert data scientist with an expertise in building deep learning models. \n",
    "Explain the concept of {concept} in a couple of lines\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"concept\"],\n",
    "    template=template)\n",
    "print(prompt.format(concept=\"asdf\"))\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"2+2\", \"output\": \"4\"},\n",
    "    {\"input\": \"2+3\", \"output\": \"5\"}]\n",
    "\n",
    "# This is a prompt template used to format each individual example.\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \" our input is :{input}\"),\n",
    "        (\"ai\", \" final output is :{output}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic definition and examples : Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adarsh.a.kumar.gupta\\OneDrive - Accenture\\Desktop\\accenture\\rag\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ! pip install peft\n",
    "# ! pip install transformers datasets torch\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# Specify the dataset name and the column containing the content\n",
    "token=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset (e.g., the IMDb dataset for sentiment analysis)\n",
    "dataset = load_dataset(\"imdb\")\n",
    "dataset[\"train\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "l=len(tokenized_datasets[\"train\"][\"input_ids\"][123])\n",
    "print(l)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(2000))  # Use a subset for quick training\n",
    "eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(500))  # Use a subset for quick evaluation\n",
    "\n",
    "\n",
    "# Load a pre-trained model for sequence classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "# lets see what will hapen we will give 5 classification task\n",
    "model1 = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5714,  0.2107]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets explaore: decode , encoded input  and other functionalities of this bert model\n",
    "model.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# User input text\n",
    "user_text = \"hi i am adarsh\"\n",
    "\n",
    "# Tokenize the input text\n",
    "# input_ids\n",
    "# token_type_ids\n",
    "# attention_mask_ids: same as below -\n",
    "\"\"\"\n",
    "(word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
    "(position_embeddings): Embedding(512, 768)\n",
    "(token_type_embeddings): Embedding(2, 768)\n",
    "\"\"\"\n",
    "inputs = tokenizer(user_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "inputs\n",
    "\n",
    "# inputs = tokenizer.decode(inputs[\"input_ids\"][0])\n",
    "# tokenizer.convert_ids_to_tokens(2232)\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    pred = model(**inputs)\n",
    "\n",
    "# Get the logits (raw predictions)\n",
    "logits = pred.logits\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation for fine tuning\n",
    "# batch size : per_device_eval_batch_size yahi hota for train and val set\n",
    "# epochs: no of times a dataset voisited\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\", # trained model will be saved\n",
    "    eval_strategy=\"epoch\",  # at end of every epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,  # Reduce batch size for CPU, it means batch saples\n",
    "    per_device_eval_batch_size=1,   # Reduce batch size for CPU\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,  # regularization technique\n",
    "    gradient_accumulation_steps=8,  # Accumulate gradients to simulate larger batch size\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# loss function  calculation way\n",
    "\"\"\"    classification: score will comapre with actual using cross entropy function\n",
    "       NER: for each token logit score will come, calculate loss with score of individual token and add it for all to get final loss\n",
    "       Text prediction:  check only correect prediction of start and end position tokens\n",
    "       question: \"--------\"\n",
    "       gpt_answer: \"start_token_gpt_1 ------------ end_token_gpt_1\"\n",
    "       user_answer=\" start_token_actual_2 --------------end_token_actual_2\"\n",
    "           1- loss=loss(start_token_gpt_1, start_token_actaul_1)+loss(end_token_gpt_2, end_token_actaul_2)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Data collator that will dynamically pad the inputs received\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# tokenizer: text-> token-> add_special_tokens -> to_numerical\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4016,  1.2502]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name=\"results\\checkpoint-750\"\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model=AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.eval()\n",
    "model.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# User input text\n",
    "user_text = \"hi i am adarsh\"\n",
    "\n",
    "# Tokenize the input text\n",
    "# input_ids\n",
    "# token_type_ids\n",
    "# attention_mask_ids: same as below -\n",
    "\"\"\"\n",
    "(word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
    "(position_embeddings): Embedding(512, 768)\n",
    "(token_type_embeddings): Embedding(2, 768)\n",
    "\"\"\"\n",
    "inputs = tokenizer(user_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "inputs\n",
    "\n",
    "# inputs = tokenizer.decode(inputs[\"input_ids\"][0])\n",
    "# tokenizer.convert_ids_to_tokens(2232)\n",
    "# token_type_ids= differntiate which is question patt and which is answer part, \n",
    "# tokenizer(question, answer)\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    pred = model(**inputs)\n",
    "\n",
    "# Get the logits (raw predictions)\n",
    "logits = pred.logits\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]\n",
      "hi\n",
      "i\n",
      "am\n",
      "ada\n",
      "##rs\n",
      "##h\n",
      "[SEP]\n",
      "hi\n",
      "i\n",
      "am\n",
      "ada\n",
      "##rs\n",
      "##h\n",
      "[SEP]\n",
      "[PAD]\n",
      "[PAD]\n",
      "[PAD]\n",
      "[PAD]\n",
      "[PAD]\n",
      "[PAD]\n",
      "[PAD]\n",
      "[PAD]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a=[  101,  7632,  1045,  2572, 15262,  2869,  2232,   102,  7632,  1045,\n",
    "          2572, 15262,  2869,  2232,   102,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0]\n",
    "for i in a:\n",
    "    p=tokenizer.convert_ids_to_tokens(i)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi i am adarsh', ' you are a manufacting bot with ai']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  7632,  1045,  2572, 15262,  2869,  2232,   102,  7632,  1045,\n",
       "          2572, 15262,  2869,  2232,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,  2017,  2024,  1037,  2158, 16093, 18908,  2075, 28516,  2007,\n",
       "          9932,   102,  2017,  2024,  1037,  2158, 16093, 18908,  2075, 28516,\n",
       "          2007,  9932,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_text = [\"hi i am adarsh\",\" you are a manufacting bot with ai\"]\n",
    "print(user_text)\n",
    "inputs = tokenizer(user_text,user_text,  return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi i am adarsh you are a manufacting bot with ai\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  7632,  1045,  2572, 15262,  2869,  2232,  2017,  2024,  1037,\n",
       "          2158, 16093, 18908,  2075, 28516,  2007,  9932,   102,  7632,  1045,\n",
       "          2572, 15262,  2869,  2232,  2017,  2024,  1037,  2158, 16093, 18908,\n",
       "          2075, 28516,  2007,  9932,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_text = \"hi i am adarsh you are a manufacting bot with ai\"\n",
    "print(user_text)\n",
    "inputs = tokenizer(user_text, user_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answer Fine Tuning\n",
    "### need gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adarsh.a.kumar.gupta\\OneDrive - Accenture\\Desktop\\accenture\\rag\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import Trainer\n",
    "from transformers import DataCollatorWithPadding # select batches of data and then pad it if not done during tokenization\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# Specify the dataset name and the column containing the content\n",
    "token=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since squad couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at C:\\Users\\adarsh.a.kumar.gupta\\.cache\\huggingface\\datasets\\squad\\plain_text\\0.0.0\\7b6d24c440a36b6815f21b70d25016731768db1f (last modified on Sat Sep 14 13:18:58 2024).\n",
      "Using the latest cached version of the dataset since squad couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at C:\\Users\\adarsh.a.kumar.gupta\\.cache\\huggingface\\datasets\\squad\\plain_text\\0.0.0\\7b6d24c440a36b6815f21b70d25016731768db1f (last modified on Sat Sep 14 13:18:58 2024).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '56be4db0acb8001400a502ec', 'title': 'Super_Bowl_50', 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.', 'question': 'Which NFL team represented the AFC at Super Bowl 50?', 'answers': {'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'], 'answer_start': [177, 177, 177]}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_dataset_name = \"squad\"\n",
    "dataset_train = load_dataset(huggingface_dataset_name,split=\"train[:5000]\")\n",
    "dataset_val= load_dataset(huggingface_dataset_name,split=\"validation[:1000]\")\n",
    "print(dataset_val[0])\n",
    "dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLS token: [CLS]\n",
      "SEP token: [SEP]\n",
      "PAD token: [PAD]\n",
      "UNK token: [UNK]\n",
      "MASK token: [MASK]\n",
      "eos token: None\n",
      "pad token: [PAD]\n",
      "CLS token ID: 101\n",
      "SEP token ID: 102\n",
      "PAD token ID: 0\n",
      "UNK token ID: 100\n",
      "MASK token ID: 103\n",
      "eos token: None\n",
      "pad token: 0\n",
      "right\n"
     ]
    }
   ],
   "source": [
    "model_name1=\"distilbert/distilbert-base-uncased\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name1);\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name1)\n",
    "\n",
    "# eval_tokenizer = AutoTokenizer.from_pretrained(model_name1, add_bos_token=True, trust_remote_code=True, use_fast=False)\n",
    "# special_tokens_dict = {'eos_token': '[EOS]', 'pad_token': '[PAD]'}\n",
    "# tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "# bert not use eos token, use [sep]  instead\n",
    "# Check special tokens\n",
    "print(\"CLS token:\", tokenizer.cls_token)\n",
    "print(\"SEP token:\", tokenizer.sep_token)\n",
    "print(\"PAD token:\", tokenizer.pad_token)\n",
    "print(\"UNK token:\", tokenizer.unk_token)\n",
    "print(\"MASK token:\", tokenizer.mask_token)\n",
    "print(\"eos token:\", tokenizer.eos_token)\n",
    "print(\"pad token:\", tokenizer.pad_token)\n",
    "\n",
    "# Check special token IDs\n",
    "print(\"CLS token ID:\", tokenizer.cls_token_id)\n",
    "print(\"SEP token ID:\", tokenizer.sep_token_id)\n",
    "print(\"PAD token ID:\", tokenizer.pad_token_id)\n",
    "print(\"UNK token ID:\", tokenizer.unk_token_id)\n",
    "print(\"MASK token ID:\", tokenizer.mask_token_id)\n",
    "print(\"eos token:\", tokenizer.eos_token_id)\n",
    "print(\"pad token:\", tokenizer.pad_token_id)\n",
    "\n",
    "print(tokenizer.padding_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForQuestionAnswering(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2000, 3183, 2106, 1996, 6261, 2984, 9382, 3711, 1999, 8517, 1999, 10223, 26371, 2605, 1029, 102, 6549, 2135, 1010, 1996, 2082, 2038, 1037, 3234, 2839, 1012, 10234, 1996, 2364, 2311, 1005, 1055, 2751, 8514, 2003, 1037, 3585, 6231, 1997, 1996, 6261, 2984, 1012, 3202, 1999, 2392, 1997, 1996, 2364, 2311, 1998, 5307, 2009, 1010, 2003, 1037, 6967, 6231, 1997, 4828, 2007, 2608, 2039, 14995, 6924, 2007, 1996, 5722, 1000, 2310, 3490, 2618, 4748, 2033, 18168, 5267, 1000, 1012, 2279, 2000, 1996, 2364, 2311, 2003, 1996, 13546, 1997, 1996, 6730, 2540, 1012, 3202, 2369, 1996, 13546, 2003, 1996, 24665, 23052, 1010, 1037, 14042, 2173, 1997, 7083, 1998, 9185, 1012, 2009, 2003, 102], [101, 2000, 3183, 2106, 1996, 6261, 2984, 9382, 3711, 1999, 8517, 1999, 10223, 26371, 2605, 1029, 102, 13546, 2003, 1996, 24665, 23052, 1010, 1037, 14042, 2173, 1997, 7083, 1998, 9185, 1012, 2009, 2003, 1037, 15059, 1997, 1996, 24665, 23052, 2012, 10223, 26371, 1010, 2605, 2073, 1996, 6261, 2984, 22353, 2135, 2596, 2000, 3002, 16595, 9648, 4674, 2061, 12083, 9711, 2271, 1999, 8517, 1012, 2012, 1996, 2203, 1997, 1996, 2364, 3298, 1006, 1998, 1999, 1037, 3622, 2240, 2008, 8539, 2083, 1017, 11342, 1998, 1996, 2751, 8514, 1007, 1010, 2003, 1037, 3722, 1010, 2715, 2962, 6231, 1997, 2984, 1012, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'overflow_to_sample_mapping': [0, 0]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[112, 98]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_example = tokenizer(\n",
    "    dataset_train[0][\"question\"],\n",
    "    dataset_train[0][\"context\"],\n",
    "    max_length=112,\n",
    "    truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    stride=16,\n",
    "    \n",
    ")\n",
    "print(tokenized_example)\n",
    "tokenized_example.keys()\n",
    "[len(i) for i in tokenized_example[\"input_ids\"] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5000/5000 [00:06<00:00, 742.19 examples/s]\n",
      "Map: 100%|██████████| 1000/1000 [00:01<00:00, 879.65 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " wrong preprocessing and respective samples\n",
      "val :---------------------------------------------   \n",
      "\" golden anniversary \" \"golden anniversary\"\n",
      "\" golden anniversary \" \"golden anniversary\"\n",
      "24 – 10 24–10\n",
      " 8\n",
      "15 – 1 15–1\n",
      "12 – 4 12–4\n",
      " 2\n",
      " 5\n",
      " 5\n",
      "$ 5 million $5 million\n",
      "beyonce and bruno mars beyoncé and bruno mars\n",
      "$ 5 million $5 million\n",
      "beyonce beyoncé\n",
      "$ 5 million $5 million\n",
      "$ 5 million $5 million\n",
      "beyonce and bruno mars beyoncé and bruno mars\n",
      "beyonce and bruno mars beyoncé and bruno mars\n",
      "$ 5 million $5 million\n",
      "beyonce and bruno mars beyoncé and bruno mars\n",
      "new orleans'mercedes - benz superdome new orleans' mercedes-benz superdome\n",
      "mercedes - benz superdome mercedes-benz superdome\n",
      "new orleans'mercedes - benz superdome, miami's sun life stadium, and the san francisco bay area's levi's stadium new orleans' mercedes-benz superdome, miami's sun life stadium, and the san francisco bay area's levi's stadium\n",
      "mercedes - benz superdome mercedes-benz superdome\n",
      " 10.\n",
      "$ 1. 2 billion $1.2 billion\n",
      "$ 1. 2 billion $1.2 billion\n",
      "$ 1. 2 billion $1.2 billion\n",
      "$ 1. 2 billion $1.2 billion\n",
      " 7\n",
      "99. 4 99.4\n",
      "3, 837 3,837\n",
      "3, 837 3,837\n",
      "99. 4. 99.4.\n",
      "67. 9 67.9\n",
      "67. 9 67.9\n",
      "2, 249 2,249\n",
      "67. 9 67.9\n",
      " 5\n",
      "67. 9 67.9\n",
      "4. 7 4.7\n",
      "4, 530 4,530\n",
      "31 – 24 31–24\n",
      "31 – 24 31–24\n",
      "49 – 15 49–15\n",
      "20 – 18 20–18\n",
      "23 – 16 23–16\n",
      "34 – 19 34–19\n",
      "34 – 19 34–19\n",
      "the 50 - yard line the 50-yard line\n",
      "$ 5 million. $5 million.\n",
      "$ 2 million $2 million\n",
      "$ 2 million $2 million\n",
      "$ 2 million $2 million\n",
      "$ 40 million $40 million\n",
      "over $ 40 million over $40 million\n",
      "over $ 40 million over $40 million\n",
      "18 - karat gold - plated 18-karat gold-plated\n",
      "360 - degree 360-degree\n",
      "cbssports. com cbssports.com\n",
      "cbssports. com cbssports.com\n",
      "$ 5, 000, 000 $5,000,000\n",
      "anheuser - busch inbev anheuser-busch inbev\n",
      "$ 5, 000, 000 $5,000,000\n",
      "anheuser - busch inbev anheuser-busch inbev\n",
      "the pokemon company the pokémon company\n",
      "anheuser - busch inbev anheuser-busch inbev\n",
      "anheuser - busch inbev anheuser-busch inbev\n",
      "\" small business big game \" \"small business big game\"\n",
      "30 - second 30-second\n",
      " ten\n",
      "teenage mutant ninja turtles : out of the shadows teenage mutant ninja turtles: out of the shadows\n",
      "teenage mutant ninja turtles : out of the shadows teenage mutant ninja turtles: out of the shadows\n",
      "captain america : civil war captain america: civil war\n",
      " two\n",
      "pre - game and halftime coverage. pre-game and halftime coverage.\n",
      "koa ( 850 am ) and krfx ( 103. 5 fm ) koa (850 am) and krfx (103.5 fm)\n",
      "wbt - fm ( 99. 3 fm ) wbt-fm (99.3 fm)\n",
      "\" hymn for the weekend \" \"hymn for the weekend\"\n",
      "\" hymn for the weekend \" \"hymn for the weekend\"\n",
      "beyonce beyoncé\n",
      "11 : 28 11:28\n",
      "26 - yard line 26-yard line\n",
      "41 - yard line. 41-yard line.\n",
      "50 - yard line. 50-yard line.\n",
      "50 - yard line. 50-yard line.\n",
      "39 - yard 39-yard\n",
      " wards\n",
      "3 : 08 3:08\n",
      "4 : 51 4:51\n",
      " wards\n",
      "maria skłodowska - curie maria skłodowska-curie\n",
      "krasinski palace garden krasiński palace garden\n",
      "833, 500 833,500\n",
      "around 34 % around 34%\n",
      "2, 000 2,000\n",
      "10, 000 m2 10,000 m2\n",
      "three - year plan three-year plan\n",
      "maria skłodowska - curie institute of oncology maria skłodowska-curie institute of oncology\n",
      "ogrod saski ogród saski\n",
      "midsummer ’ s night midsummer’s night\n",
      "katyn katyń\n",
      "royal ujazdow castle royal ujazdów castle\n",
      "zacheta national gallery of art zachęta national gallery of art\n",
      "since at least the mid - 14th century since at least the mid-14th century\n",
      "krakow kraków\n",
      "12th / 13th - century nobleman 12th/13th-century nobleman\n",
      "jazdow jazdów\n",
      "some 30 % of the city some 30% of the city\n",
      "between 150, 000 and 200, 000 between 150,000 and 200,000\n",
      "\" bricks for warsaw \" \"bricks for warsaw\"\n",
      "growing anti - communist fervor growing anti-communist fervor\n",
      "452. 8 ft 452.8 ft\n",
      "1688 – 1692 1688–1692\n",
      "1775 – 1795 1775–1795\n",
      "train--------------------------------------------\n",
      "u. s. news & world report u.s. news & world report\n",
      "department of pre - professional studies department of pre-professional studies\n",
      "3, 577 3,577\n",
      "19. 7 % 19.7%\n",
      "39. 1 % 39.1%\n",
      "57. 6 % 57.6%\n",
      "father joseph carrier, c. s. c. father joseph carrier, c.s.c.\n",
      "1851 – 1921 1851–1921\n",
      "8, 448 8,448\n",
      "21 – 24 % 21–24%\n",
      "12, 179 12,179\n",
      "80 % 80%\n",
      "20 % 20%\n",
      "more than 93 % more than 93%\n",
      "fifty - seven fifty-seven\n",
      "over 80 % over 80%\n",
      "a week - long klavern a week-long klavern\n",
      "rev. john j. cavanaugh, c. s. c. rev. john j. cavanaugh, c.s.c.\n",
      "1917 – 2015 1917–2015\n",
      "$ 9 million $9 million\n",
      "1952 – 87 1952–87\n",
      "1987 – 2005 1987–2005\n",
      "$ 350 million $350 million\n",
      "more than $ 70 million more than $70 million\n",
      "$ 400m $400m\n",
      "83, 000 square feet 83,000 square feet\n",
      "$ 1. 2 million $1.2 million\n",
      "40 % 40%\n",
      "over 1, 200 over 1,200\n",
      "five - year five-year\n",
      "1, 250 1,250\n",
      "celestine guynemer de la hailandiere célestine guynemer de la hailandière\n",
      "wsnd - fm wsnd-fm\n",
      "$ 215 million $215 million\n",
      "non - union workers non-union workers\n",
      "almost $ 100 million almost $100 million\n",
      "80, 795 80,795\n",
      "two - story banner two-story banner\n",
      "the drummers'circle the drummers' circle\n",
      "over 1, 600 over 1,600\n",
      "beyonce giselle knowles - carter beyoncé giselle knowles-carter\n",
      "beyonce beyoncé\n",
      "modern - day feminist modern-day feminist\n",
      "african - american african-american\n",
      "beyonce's father beyoncé's father\n",
      "\" say my name \" \"say my name\"\n",
      " split with luckett and rober\n",
      "beyonce beyoncé\n",
      "663, 000 copies 663,000 copies\n",
      "carmen : a hip hopera carmen: a hip hopera\n",
      "541, 000 541,000\n",
      "deja vu déjà vu\n",
      "twenty - fifth birthday twenty-fifth birthday\n",
      "541, 000 541,000\n",
      "158. 8 million 158.8 million\n",
      "the beyonce experience the beyoncé experience\n",
      "the beyonce experience the beyoncé experience\n",
      "119. 5 million 119.5 million\n",
      "119. 5 million 119.5 million\n",
      " six\n",
      "310, 000 copies 310,000 copies\n",
      "310, 000 310,000\n",
      "268, 000 tweets per minute 268,000 tweets per minute\n",
      "' 03 bonnie & clyde '03 bonnie & clyde\n",
      "12. 4 million 12.4 million\n",
      "12. 4 million 12.4 million\n",
      "lifeandtimes. com lifeandtimes.com\n",
      "b. i. c. b.i.c.\n",
      "b. i. c. b.i.c.\n",
      "angela merkel and nkosazana dlamini - zuma angela merkel and nkosazana dlamini-zuma\n",
      "angela merkel and nkosazana dlamini - zuma angela merkel and nkosazana dlamini-zuma\n",
      "highest - earning power couple highest-earning power couple\n",
      "r & b r&b\n",
      "re - release of b'day re-release of b'day\n",
      "r & b r&b\n",
      "r & b r&b\n",
      "female - empowerment female-empowerment\n",
      "man - tending anthems man-tending anthems\n",
      "co - producing credits co-producing credits\n",
      "co - producing co-producing\n",
      "beyonce beyoncé\n",
      "deja vu déjà vu\n",
      "jean - michel basquiat jean-michel basquiat\n",
      "montina cooper - donnell, crystal collins and tiffany monique riddick montina cooper-donnell, crystal collins and tiffany moniqué riddick\n",
      "l. a. reid l.a. reid\n",
      "l. a. reid l.a. reid\n",
      "making of \" crazy in love \" making of \"crazy in love\"\n",
      "revel presents : beyonce live revel presents: beyoncé live\n",
      "wide - ranging wide-ranging\n",
      "toure touré\n",
      "toure touré\n",
      "tom ford's spring / summer 2011 fashion show tom ford's spring/summer 2011 fashion show\n",
      "house of dereon house of deréon\n",
      "house of dereon. house of deréon.\n",
      "african - american african-american\n",
      "l'oreal l'oréal\n",
      "l'oreal l'oréal\n",
      "h & m h&m\n",
      "beyonce's pepsi commercial beyoncé's pepsi commercial\n",
      "beyonce beyoncé\n",
      "\" single ladies ( put a ring on it ) \" \"single ladies (put a ring on it)\"\n",
      "the center for science in the public interest ( cspinet ) the center for science in the public interest (cspinet)\n",
      "$ 50 million $50 million\n",
      "the center for science in the public interest ( cspinet ) the center for science in the public interest (cspinet)\n",
      "beyonce beyoncé\n",
      "starpower : beyonce starpower: beyoncé\n",
      "starpower : beyonce starpower: beyoncé\n",
      "starpower : beyonce starpower: beyoncé\n",
      "agnez dereon agnèz deréon\n",
      "grandmother, agnez dereon grandmother, agnèz deréon\n",
      "dereon. deréon.\n",
      "house of dereon collection house of deréon collection\n",
      "sasha fierce for dereon sasha fierce for deréon\n",
      "beyonce fashion diva beyoncé fashion diva\n",
      "sasha fierce for dereon sasha fierce for deréon\n",
      "c & a c&a\n",
      "250, 000 250,000\n",
      "$ 250, 000 $250,000\n",
      "$ 250, 000. $250,000.\n",
      "$ 1 million $1 million\n",
      "beyonce cosmetology center at the brooklyn phoenix house beyoncé cosmetology center at the brooklyn phoenix house\n",
      "new york police and fire widows'and children's benefit fund new york police and fire widows' and children's benefit fund\n",
      "hope for haiti now : a global benefit hope for haiti now: a global benefit\n",
      "beyonce cosmetology center beyoncé cosmetology center\n",
      "spanish word montana ( mountain ) spanish word montaña (mountain)\n",
      "from the spanish word montana from the spanish word montaña\n",
      "\" gold and silver \" \"gold and silver\"\n",
      "\" mountain \" \"mountain\"\n",
      "montana del norte montaña del norte\n",
      "147, 040 square miles 147,040 square miles\n",
      "over 10, 000 feet over 10,000 feet\n",
      "12, 799 feet 12,799 feet\n",
      "$ 1. 75 $1.75\n",
      "at least 3, 223 at least 3,223\n",
      "34. 70 inches 34.70 inches\n",
      "6. 9 percent 6.9 percent\n",
      "approximately 66, 000 approximately 66,000\n",
      "63 % 63%\n",
      "6. 5 percent 6.5 percent\n",
      "94. 8 percent 94.8 percent\n",
      "13, 040 13,040\n",
      "about 1, 700 about 1,700\n",
      "89. 4 percent 89.4 percent\n",
      "6. 3 percent 6.3 percent\n",
      "2. 9 2.9\n",
      "1, 032, 949 1,032,949\n",
      "4. 40 % 4.40%\n",
      "smokejumpers and for other forest fire - fighting duties. smokejumpers and for other forest fire-fighting duties.\n",
      "$. 25 $.25\n",
      "criminalized criticism of the u. s. government, military, or symbols through speech or other means criminalized criticism of the u.s. government, military, or symbols through speech or other means\n",
      "40, 000 - plus 40,000-plus\n",
      "over 57, 000 over 57,000\n",
      "first special service force or \" devil's brigade, \" first special service force or \"devil's brigade,\"\n",
      "\" in whole or in part \" \"in whole or in part\"\n",
      "that biological - physical destruction was necessary that biological-physical destruction was necessary\n",
      "biological - physical biological-physical\n",
      "\" ritualcide \" \"ritualcide\"\n",
      "the word genocide is the combination of the greek prefix geno - ( meaning tribe or race ) and caedere ( the latin word for to kill ). the word genocide is the combination of the greek prefix geno- (meaning tribe or race) and caedere (the latin word for to kill).\n",
      "as \" a crime without a name \" as \"a crime without a name\"\n",
      "greek prefix geno - ( meaning tribe or race ) and caedere ( the latin word for to kill ) greek prefix geno- (meaning tribe or race) and caedere (the latin word for to kill)\n",
      "perpetrators'access to the victims perpetrators' access to the victims\n",
      "jonassohn and bjornson jonassohn and björnson\n",
      "radovan karadzic and ratko mladic radovan karadžić and ratko mladić\n",
      "slobodan milosevic slobodan milošević\n",
      "international criminal tribunal for rwanda ( ictr ) international criminal tribunal for rwanda (ictr)\n",
      " evolution\n",
      "luria – delbruck luria–delbrück\n",
      "( macrolides, lincosamides and tetracyclines (macrolides, lincosamides and tetracyclines\n",
      "beta - lactam antibiotics beta-lactam antibiotics\n",
      "additional side - effects additional side-effects\n",
      "about 1 % about 1%\n",
      "about 1 % about 1%\n",
      "about 1 % about 1%\n",
      "there are specific types of antibiotics with which alcohol consumption may cause serious side - effects there are specific types of antibiotics with which alcohol consumption may cause serious side-effects\n",
      "specific types of antibiotics with which alcohol consumption may cause serious side - effects specific types of antibiotics with which alcohol consumption may cause serious side-effects\n",
      "mdr - tb mdr-tb\n",
      "us centers for disease control and prevention, the food and drug administration ( fda ), and the national institutes of health ( nih ) us centers for disease control and prevention, the food and drug administration (fda), and the national institutes of health (nih)\n",
      "american society for microbiology ( asm ), american public health association ( apha ) and the american medical association ( ama ) american society for microbiology (asm), american public health association (apha) and the american medical association (ama)\n",
      "s. 742 and h. r. 2562 s.742 and h.r. 2562\n",
      "american holistic nurses'association, the american medical association, and the american public health association ( apha ) american holistic nurses' association, the american medical association, and the american public health association (apha)\n",
      "phages will infect \" good \" bacteria phages will infect \"good\" bacteria\n",
      "maria wodzinska maria wodzińska\n",
      "zelazowa wola żelazowa wola\n",
      "zelazowa wola żelazowa wola\n",
      "zelazowa wola żelazowa wola\n",
      "justyna krzyzanowska justyna krzyżanowska\n",
      "justyna krzyzanowska justyna krzyżanowska\n",
      "wojciech zywny wojciech żywny\n",
      " 7\n",
      "a polonaise in a - flat major of 1821 a polonaise in a-flat major of 1821\n",
      "wojciech zywny wojciech żywny\n",
      " 7\n",
      "wojciech zywny wojciech żywny\n",
      " 7\n",
      "wojciech zywny wojciech żywny\n",
      "jozef elsner józef elsner\n",
      "wilhelm wurfel wilhelm würfel\n",
      "jozef elsner józef elsner\n",
      "wilhelm wurfel wilhelm würfel\n",
      "jozef elsner józef elsner\n",
      "krakowskie przedmiescie krakowskie przedmieście\n",
      "ambrozy mieroszewski ambroży mieroszewski\n",
      "ambrozy mieroszewski ambroży mieroszewski\n",
      "ambrozy mieroszewski ambroży mieroszewski\n",
      "jan matuszynski and julian fontana jan matuszyński and julian fontana\n",
      "tytus woyciechowski, jan nepomucen białobłocki, jan matuszynski and julian fontana tytus woyciechowski, jan nepomucen białobłocki, jan matuszyński and julian fontana\n",
      "piano concerto no. 1 ( in e minor ) piano concerto no. 1 (in e minor)\n",
      "jan matuszynski and julian fontana jan matuszyński and julian fontana\n",
      "piano concerto no. 1 ( in e minor ) piano concerto no. 1 (in e minor)\n",
      "accustomed to the piano - bashing of local artists accustomed to the piano-bashing of local artists\n",
      "niccolo paganini niccolò paganini\n",
      "\" i curse the moment of my departure. \" \"i curse the moment of my departure.\"\n",
      "hector berlioz, franz liszt, ferdinand hiller, heinrich heine, eugene delacroix, and alfred de vigny hector berlioz, franz liszt, ferdinand hiller, heinrich heine, eugène delacroix, and alfred de vigny\n",
      "countess wodzinska countess wodzińska\n",
      "dusseldorf düsseldorf\n",
      "38 rue de la chaussee - d'antin 38 rue de la chaussée-d'antin\n",
      "the hotel de france on the rue lafitte the hôtel de france on the rue lafitte\n",
      "love - hate relationship love-hate relationship\n",
      "op. 10 etudes op. 10 études\n",
      "felicien mallefille félicien mallefille\n",
      "felicien mallefille. félicien mallefille.\n",
      "square d'orleans square d'orléans\n",
      "square d'orleans square d'orléans\n",
      "square d'orleans square d'orléans\n",
      "berlioz's grande symphonie funebre et triomphale berlioz's grande symphonie funèbre et triomphale\n",
      "berlioz's grande symphonie funebre et triomphale berlioz's grande symphonie funèbre et triomphale\n",
      "polonaise in a - flat major, op. 53 polonaise in a-flat major, op. 53\n",
      "delacroix and the mezzo - soprano pauline viardot delacroix and the mezzo-soprano pauline viardot\n",
      "charles halle charles hallé\n",
      "auguste clesinger auguste clésinger\n",
      "auguste clesinger auguste clésinger\n",
      "auguste clesinger. auguste clésinger.\n",
      " opera\n",
      "marcel proust and andre gide marcel proust and andré gide\n",
      "methuen - campbell methuen-campbell\n",
      "1, 500 1,500\n",
      "nearly 1, 500 nearly 1,500\n",
      "adam łyszczynski adam łyszczyński\n",
      "place vendome 12 place vendôme 12\n",
      "\" no longer \" \"no longer\"\n",
      "clesinger clésinger\n",
      "over 3, 000 over 3,000\n",
      "over 3, 000 over 3,000\n",
      "louis lefebure - wely louis lefébure-wély\n",
      "louis lefebure - wely louis lefébure-wély\n",
      "pere lachaise cemetery père lachaise cemetery\n",
      "clesinger clésinger\n",
      "5, 000 francs 5,000 francs\n",
      "clesinger. clésinger.\n",
      "5, 000 francs 5,000 francs\n",
      "concert etude concert étude\n",
      "the revolutionary etude the revolutionary étude\n",
      "revolutionary etude revolutionary étude\n",
      "krystyna kobylanska krystyna kobylańska\n",
      "the kobylanska catalogue the kobylańska catalogue\n",
      "krystyna kobylanska. krystyna kobylańska.\n",
      "breitkopf & hartel breitkopf & härtel\n",
      "popular 19th - century piano anthologies. popular 19th-century piano anthologies.\n",
      "the four - bar phrase the four-bar phrase\n",
      "his flexible handling of the four - bar phrase as a structural unit. his flexible handling of the four-bar phrase as a structural unit.\n",
      "etudes études\n",
      "etudes études\n",
      "the well - tempered clavier the well-tempered clavier\n",
      "j. s. bach's the well - tempered clavier j.s. bach's the well-tempered clavier\n",
      "leon escudier léon escudier\n",
      "his projet de methode his projet de méthode\n",
      "\" always crescendo to a high note \" \"always crescendo to a high note\"\n",
      "friederike muller friederike müller\n",
      "friederike muller friederike müller\n",
      "carolyne zu sayn - wittgenstein carolyne zu sayn-wittgenstein\n",
      "carolyne zu sayn - wittgenstein carolyne zu sayn-wittgenstein\n",
      "michał kleofas oginski and franciszek lessel michał kleofas ogiński and franciszek lessel\n",
      "1402 – 1424 1402–1424\n",
      "907 – 960 907–960\n",
      "960 – 1279 960–1279\n",
      "ogedei khan ögedei khan\n",
      "1229 – 1241 1229–1241\n",
      "ogedei khan ögedei khan\n",
      "toregene khatun töregene khatun\n",
      "1241 – 1246 1241–1246\n",
      "ogedei khan ögedei khan\n",
      "1271 – 1368 1271–1368\n",
      "1368 – 1398 1368–1398\n",
      "1402 – 1424 1402–1424\n",
      "1644 – 1912 1644–1912\n",
      "e - li - si army - civilian marshal office é-lì-sī army-civilian marshal office\n",
      "a non - chinese polity a non-chinese polity\n",
      "1311 – 1320 1311–1320\n",
      "ming dynasty's u - tsang commanding office ming dynasty's ü-tsang commanding office\n",
      "1, 000 households 1,000 households\n",
      "10, 000 households 10,000 households\n",
      "his disciple chosrje shakya yeshes his disciple chosrje shākya yeshes\n",
      "1435 – 1565 1435–1565\n",
      "1565 – 1642 1565–1642\n",
      "1398 – 1402 1398–1402\n",
      "josef kolmas josef kolmaš\n",
      "1435 – 1449 1435–1449\n",
      "through sichuan and crossed shangri - la county in yunnan through sichuan and crossed shangri-la county in yunnan\n",
      "a mandatory \" corvee \" tax a mandatory \"corvée\" tax\n",
      "30, 000 30,000\n",
      "200, 000 200,000\n",
      "divide - and - rule divide-and-rule\n",
      "1505 – 1521 1505–1521\n",
      "mikyo dorje mikyö dorje\n",
      "1521 – 1567 1521–1567\n",
      "neo - confucian establishment neo-confucian establishment\n",
      "the third hierarch of the gelug — sonam gyatso the third hierarch of the gelug—sönam gyatso\n",
      "tumen khan tümen khan\n",
      "the great - grandson of altan khan the great-grandson of altan khan\n",
      "1611 – 1621 1611–1621\n",
      "the mongol prince gushi khan the mongol prince güshi khan\n",
      "the regent sonam chopel the regent sonam chöpel\n",
      "gushi khan güshi khan\n",
      "1735 – 1796 1735–1796\n",
      " 3\n",
      " one\n",
      "\" music \" and \" videos \" \"music\" and \"videos\"\n",
      "burst. com burst.com\n",
      "burst. com burst.com\n",
      "2001 : a space odyssey 2001: a space odyssey\n",
      "2001 : a space odyssey 2001: a space odyssey\n",
      "mid - 2015 mid-2015\n",
      "12. 2 12.2\n",
      "12. 2 12.2\n",
      "high - impedance high-impedance\n",
      "undersized dc - blocking capacitors undersized dc-blocking capacitors\n",
      "r & b, rock, acoustic, and bass booster r&b, rock, acoustic, and bass booster\n",
      "r & b, rock, acoustic, and bass booster r&b, rock, acoustic, and bass booster\n",
      "30 - pin dock connector 30-pin dock connector\n",
      "3. 5 mm minijack 3.5 mm minijack\n",
      "ipod hi - fi ipod hi-fi\n",
      "ipod hi - fi ipod hi-fi\n",
      "ipod hi - fi ipod hi-fi\n",
      "nike + ipod pedometer nike+ipod pedometer\n",
      "individual seat - back displays individual seat-back displays\n",
      "mp3, aac / m4a, protected aac, aiff, wav, audible audiobook, and apple lossless mp3, aac/m4a, protected aac, aiff, wav, audible audiobook, and apple lossless\n",
      ". ipg .ipg\n",
      ". zip .zip\n",
      ". ipg .ipg\n",
      "third - party third-party\n",
      " manual\n",
      "$ 100 million $100 million\n",
      "$ 100 million $100 million\n",
      "90 % 90%\n",
      "72. 7 % 72.7%\n",
      "90 % 90%\n",
      "70 % 70%\n",
      "74 % 74%\n",
      "hewlett - packard hewlett-packard\n",
      "wal - mart wal-mart\n",
      "5 % 5%\n",
      "32 % 32%\n",
      "$ 5. 2 billion $5.2 billion\n",
      "32 % 32%\n",
      "$ 6. 22 billion $6.22 billion\n",
      "19. 22 % 19.22%\n",
      "$ 3. 5 billion $3.5 billion\n",
      "$ 15. 4 billion $15.4 billion\n",
      "$ 3. 5 billion $3.5 billion\n",
      "$ 1. 58 billion $1.58 billion\n",
      "21 % 21%\n",
      "42 % 42%\n",
      "14. 21 % 14.21%\n",
      "mp3. com mp3.com\n",
      "third - party vendors third-party vendors\n",
      "lithium - ion lithium-ion\n",
      "lithium - ion lithium-ion\n",
      "$ 99 $99\n",
      "$ 99 $99\n",
      "short life - span and fragile hard drives short life-span and fragile hard drives\n",
      "13. 7 % 13.7%\n",
      "35 % 35%\n",
      "verite verité\n",
      "verite verité\n",
      "hfs + hfs+\n",
      "action - adventure action-adventure\n",
      "l - targeting l-targeting\n",
      "action - adventure action-adventure\n",
      "l - targeting l-targeting\n",
      "on - screen display on-screen display\n",
      "context - sensitive button mechanic context-sensitive button mechanic\n",
      "on - screen display on-screen display\n",
      "small imp - like creature small imp-like creature\n",
      "akiko komoto akiko kōmoto\n",
      " japan\n",
      "akiko komoto akiko kōmoto\n",
      "pointing - based pointing-based\n",
      "michiru oshima michiru ōshima\n",
      "michiru oshima michiru ōshima\n",
      "4. 0 4.0\n",
      "3. 3 and 3. 4 3.3 and 3.4\n",
      "4. 0 4.0\n",
      "the legend of zelda : twilight princess hd the legend of zelda: twilight princess hd\n",
      "5. 82 million 5.82 million\n",
      "1. 32 million 1.32 million\n",
      "5. 82 million 5.82 million\n",
      "1. 32 million 1.32 million\n",
      "$ 245 $245\n",
      " twenty-four\n",
      " four\n",
      "metro - goldwyn - mayer and columbia pictures metro-goldwyn-mayer and columbia pictures\n",
      "lea seydoux léa seydoux\n",
      "special executive for counter - intelligence, terrorism, revenge and extortion special executive for counter-intelligence, terrorism, revenge and extortion\n",
      "warhead 2000 a. d. warhead 2000 a.d.\n",
      " four\n",
      "berenice lim marlohe bérénice lim marlohe\n",
      "berenice lim marlohe bérénice lim marlohe\n",
      " six\n",
      "aston martin db10 and a jaguar c - x75 aston martin db10 and a jaguar c-x75\n",
      "the zocalo and the centro historico district the zócalo and the centro histórico district\n",
      "1, 500 1,500\n",
      "a messerschmitt - bolkow - blohm bo 105 helicopter a messerschmitt-bölkow-blohm bo 105 helicopter\n",
      "zocalo and the centro historico district zócalo and the centro histórico district\n",
      "$ 20 million $20 million\n",
      "mission : impossible – rogue nation mission: impossible – rogue nation\n",
      "$ 879. 3 million $879.3 million\n",
      "$ 199. 8 million $199.8 million\n",
      "$ 138. 1 million $138.1 million\n",
      "£41. 7 million ( $ 63. 8 million ) £41.7 million ($63.8 million)\n",
      "$ 9. 2 million $9.2 million\n",
      "4 % 4%\n",
      "spider - man 3 spider-man 3\n",
      "$ 8. 2 million $8.2 million\n",
      "spider - man 3 spider-man 3\n",
      "$ 70. 4 million $70.4 million\n",
      "$ 5. 25 $5.25\n",
      "198 % 198%\n",
      "75 % 75%\n",
      "$ 84. 7 million $84.7 million\n",
      "mission : impossible – rogue nation mission: impossible – rogue nation\n",
      "$ 84. 7 million $84.7 million\n",
      "64 % 64%\n",
      " 75\n",
      " skyfall\n",
      "69, 197 69,197\n",
      "8. 0 ms and 7. 9 mw 8.0 ms and 7.9 mw\n",
      "02 : 28 : 01 pm china standard time 02:28:01 pm china standard time\n",
      "69, 197 69,197\n",
      "69, 197 69,197\n",
      "68, 636 68,636\n",
      "4. 8 million 4.8 million\n",
      "68, 636 68,636\n",
      "374, 176 374,176\n",
      "18, 222 18,222\n",
      "4. 8 million 4.8 million\n",
      "80 % 80%\n",
      "8. 0 ms and 7. 9 mw 8.0 ms and 7.9 mw\n",
      "almost 80 % almost 80%\n",
      "along the border of the indo - australian plate and eurasian plate along the border of the indo-australian plate and eurasian plate\n",
      "yingxiu - beichuan fracture yingxiu-beichuan fracture\n",
      "6, 000 people 6,000 people\n",
      "42, 719 42,719\n",
      "6. 4 ms 6.4 ms\n",
      "ms 6. 1 ms 6.1\n",
      "3. 5 metres 3.5 metres\n",
      "2. 3 metres 2.3 metres\n",
      "3. 5 metres 3.5 metres\n",
      "3. 5 metres 3.5 metres\n",
      "4. 8 metres 4.8 metres\n",
      "80 % 80%\n",
      "80 % 80%\n",
      "2, 300 2,300\n",
      "2, 300 2,300\n",
      " 2\n",
      "2, 000 2,000\n",
      "69, 180 69,180\n",
      "68, 636 68,636\n",
      "18, 498 18,498\n",
      "374, 176 374,176\n",
      "68, 636 68,636\n",
      "69, 180 69,180\n",
      "18, 498 18,498\n",
      "374, 176 374,176\n",
      "2, 300 2,300\n",
      "9, 000 9,000\n",
      "3, 000 to 5, 000 3,000 to 5,000\n",
      "10, 000 10,000\n",
      "2, 300 2,300\n",
      "about 9, 000 about 9,000\n",
      "3, 000 to 5, 000 3,000 to 5,000\n",
      "10, 000 10,000\n",
      "1, 700 1,700\n",
      "7, 000 7,000\n",
      "1, 700 1,700\n",
      "7, 000 7,000\n",
      "5, 335 5,335\n",
      "5, 335 5,335\n",
      "12. 5 million 12.5 million\n",
      " 1 million\n",
      "12. 5 million animals 12.5 million animals\n",
      "$ 75 billion $75 billion\n",
      "us $ 75 billion us$75 billion\n",
      "420, 000 420,000\n",
      "6. 0 mw 6.0 mw\n",
      "more than 420, 000 more than 420,000\n",
      "200, 000 200,000\n",
      "1. 94 million 1.94 million\n",
      "1, 300 1,300\n",
      "90, 000 90,000\n",
      "200, 000 200,000\n",
      "685, 000 685,000\n",
      "1. 94 million 1.94 million\n",
      "50, 000 50,000\n",
      "50, 000 50,000\n",
      "at 22 : 15 cst, may 12 at 22:15 cst, may 12\n",
      "more than $ 48. 6 million more than $48.6 million\n",
      "48. 6 million 48.6 million\n",
      "$ 457 million $457 million\n",
      "€40, 000, 000 €40,000,000\n",
      "over 7. 0 over 7.0\n",
      "15, 600 15,600\n",
      "around 3, 000 around 3,000\n",
      "15, 600 15,600\n",
      "around 3, 000 around 3,000\n",
      "around 9, 000 around 9,000\n",
      "non - combat airlifting non-combat airlifting\n",
      "satellite images of the quake - stricken areas satellite images of the quake-stricken areas\n",
      "135, 000 135,000\n",
      "135, 000 135,000\n",
      "$ 772 million $772 million\n",
      "2, 500 2,500\n",
      "788, 000 yuan 788,000 yuan\n",
      "30, 000 30,000\n",
      "us $ 143, 000 us$143,000\n",
      "30, 000 30,000\n",
      "7, 000 7,000\n",
      "tofu - dregs schoolhouses tofu-dregs schoolhouses\n",
      "over 7, 000 over 7,000\n",
      "tofu - dregs schoolhouses tofu-dregs schoolhouses\n",
      "four - hour program called the giving of love four-hour program called the giving of love\n",
      "donations of the evening totalled 1. 5 billion chinese yuan donations of the evening totalled 1.5 billion chinese yuan\n",
      "$ 1. 57 million $1.57 million\n",
      "us $ 208 million us$208 million\n",
      "1. 57 million 1.57 million\n",
      "this is the first time [ that ] the chinese media has lived up to international standards this is the first time [that] the chinese media has lived up to international standards\n",
      "7. 9 7.9\n",
      "200, 000 200,000\n",
      "1, 200 1,200\n",
      "three - day period three-day period\n",
      "proactive action that spared the lives of all 2, 323 pupils in attendance when the earthquake happened proactive action that spared the lives of all 2,323 pupils in attendance when the earthquake happened\n",
      "2, 323 2,323\n",
      "400, 000 yuan 400,000 yuan\n",
      "three - year period three-year period\n",
      "to gain first - hand material of construction quality to gain first-hand material of construction quality\n",
      "one year of re - education one year of re-education\n",
      "$ 214, 000 and $ 71, 000 $214,000 and $71,000\n",
      "$ 26 million $26 million\n",
      "10. 7 billion yuan 10.7 billion yuan\n",
      "cctv - 1 cctv-1\n",
      "state - controlled media state-controlled media\n",
      "8, 491, 079 8,491,079\n",
      "23. 6 million 23.6 million\n",
      "8, 491, 079 8,491,079\n",
      "nouvelle angouleme nouvelle angoulême\n",
      "estevao gomes estêvão gomes\n",
      "padron real padrón real\n",
      "director - general director-general\n",
      "second anglo - dutch war second anglo-dutch war\n",
      "second anglo - dutch war second anglo-dutch war\n",
      "42 % 42%\n",
      "10, 000 10,000\n",
      "16, 000 16,000\n",
      "commissioners'plan commissioners' plan\n",
      "200, 000 200,000\n",
      "25 % 25%\n",
      "over 200, 000 over 200,000\n",
      "$ 300 $300\n",
      "10, 000 10,000\n",
      "1, 021 1,021\n",
      "international ladies'garment workers'union international ladies' garment workers' union\n",
      "36, 620 36,620\n",
      "36, 620 36,620\n",
      "541. 3 541.3\n",
      "468. 9 468.9\n",
      "164. 1 164.1\n",
      "304. 8 304.8\n",
      "468. 9 468.9\n",
      "164. 1 164.1\n",
      "304. 8 304.8\n",
      "409. 8 409.8\n",
      "5, 937 5,937\n",
      "wooden roof - mounted water towers wooden roof-mounted water towers\n",
      "2, 535 2,535\n",
      "0. 3 0.3\n",
      "72 % 72%\n",
      "1, 270 1,270\n",
      "49. 9 49.9\n",
      "25. 8 25.8\n",
      "10, 521. 83 10,521.83\n",
      "9, 000 9,000\n",
      "over 26, 000 over 26,000\n",
      "28, 000 28,000\n",
      "1, 093 1,093\n",
      "over 28, 000 over 28,000\n",
      "2, 700 2,700\n",
      "8, 491, 079 8,491,079\n",
      "316, 000 316,000\n",
      "40 % 40%\n",
      "40 % 40%\n",
      "8, 491, 079 8,491,079\n",
      "27, 858 27,858\n",
      "27, 673 27,673\n",
      "44 % 44%\n",
      "25. 5 % 25.5%\n",
      "28. 6 % 28.6%\n",
      "25. 5 25.5\n",
      "92 % 92%\n",
      "37 % 37%\n",
      "74, 000 74,000\n",
      "6. 3 % 6.3%\n",
      "0. 3 % 0.3%\n",
      "2. 7 million 2.7 million\n",
      "550, 000 550,000\n",
      "201, 000 201,000\n",
      "65, 000 65,000\n",
      "2. 7 million 2.7 million\n",
      "1. 5 million 1.5 million\n",
      "20 % 20%\n",
      "4. 8 million 4.8 million\n",
      "1. 3 million 1.3 million\n",
      "568, 903 568,903\n",
      "568, 903 568,903\n",
      "59 % 59%\n",
      "33 % 33%\n",
      "1. 1 million 1.1 million\n",
      "0. 5 0.5\n",
      "4. 6 % 4.6%\n",
      "$ 2, 749 $2,749\n",
      "2, 749 2,749\n",
      "us $ 914. 8 billion us$914.8 billion\n",
      "us $ 1. 1 billion us$1.1 billion\n",
      "$ 1, 589 $1,589\n",
      "$ 15, 887 $15,887\n",
      "180, 000 180,000\n",
      "$ 11 billion $11 billion\n",
      "180, 000 180,000\n",
      "19, 000 19,000\n",
      "us $ 5 billion us$5 billion\n",
      "us $ 234 million us$234 million\n",
      "163, 400 163,400\n",
      "us $ 3. 8 billion us$3.8 billion\n",
      "us $ 360, 700 us$360,700\n",
      "$ 40 billion $40 billion\n",
      "19 % 19%\n",
      "46. 5 million 46.5 million\n",
      "us $ 3 billion us$3 billion\n",
      "300, 000 300,000\n",
      "300, 000 300,000\n",
      "technion - israel institute of technology technion-israel institute of technology\n",
      "us $ 2 billion us$2 billion\n",
      "us $ 30 million us$30 million\n",
      "65, 000 65,000\n",
      "56. 4 million 56.4 million\n",
      "us $ 61. 3 billion us$61.3 billion\n",
      "56. 4 million 56.4 million\n",
      "90, 000 90,000\n",
      "10 % 10%\n",
      "us $ 1. 95 billion us$1.95 billion\n",
      "90, 000 90,000\n",
      "1. 95 billion 1.95 billion\n",
      "130, 000 130,000\n",
      "$ 7. 1 billion $7.1 billion\n",
      "25, 000 25,000\n",
      " 2\n",
      "1. 1 million 1.1 million\n",
      "1, 700 1,700\n",
      "1. 1 million 1.1 million\n",
      "600, 000 600,000\n",
      "$ 6. 7 billion $6.7 billion\n",
      "1. 4 million 1.4 million\n",
      "475, 000 475,000\n",
      "35, 000 35,000\n",
      "35, 000 35,000\n",
      "75 % 75%\n",
      "95. 9 % 95.9%\n",
      "11, 080 11,080\n",
      "3, 300 3,300\n",
      "2, 000 2,000\n",
      "12. 21 million 12.21 million\n",
      "us $ 1. 27 billion us$1.27 billion\n",
      "11. 4 % 11.4%\n",
      "12. 21 million 12.21 million\n",
      "11. 57 million 11.57 million\n",
      "24, 000 24,000\n",
      "4, 000 4,000\n",
      "24, 000 24,000\n",
      "37, 866 37,866\n",
      "1. 75 billion 1.75 billion\n",
      "38. 4 38.4\n",
      "54. 6 54.6\n",
      "54. 6 % 54.6%\n",
      "90 % 90%\n",
      "38. 4 38.4\n",
      "52 % 52%\n",
      "22 % 22%\n",
      "7, 000 7,000\n",
      "200, 000 200,000\n",
      "8. 4 8.4\n",
      "the verrazano - narrows bridge the verrazano-narrows bridge\n",
      "verrazano - narrows bridge verrazano-narrows bridge\n",
      "neo - gothic neo-gothic\n",
      "120, 000 120,000\n",
      "200, 000 200,000\n",
      "200, 000 200,000\n",
      "21 % 21%\n",
      "us $ 3. 2 billion us$3.2 billion\n",
      "20 % 20%\n",
      "four - year four-year\n",
      "67 % 67%\n",
      "43, 523 43,523\n",
      "225, 000 225,000\n",
      "one - fifth one-fifth\n",
      "pele pelé\n",
      "two - thirds two-thirds\n",
      "port authority trans - hudson port authority trans-hudson\n",
      "12, 000 12,000\n",
      "3, 715 3,715\n",
      "28 % 28%\n",
      "80 % 80%\n",
      "110, 000 110,000\n",
      "mayor - council mayor-council\n",
      "$ 11 billion $11 billion\n",
      "$ 11. 4 billion $11.4 billion\n",
      "jean louise finch ( scout ) jean louise finch (scout)\n",
      "southern gothic and coming - of - age or bildungsroman novel southern gothic and coming-of-age or bildungsroman novel\n",
      " 41\n",
      "poor rural \" white trash \" poor rural \"white trash\"\n",
      "174, 000 174,000\n",
      "30 % 30%\n",
      "3. 5 to 7. 0 3.5 to 7.0\n",
      "174, 000 174,000\n",
      "approximately 30 % approximately 30%\n",
      "150 to 300 watts per square meter or 3. 5 to 7. 0 kwh / m2 per day 150 to 300 watts per square meter or 3.5 to 7.0 kwh/m2 per day\n",
      "about 71 % about 71%\n",
      "3, 850, 000 3,850,000\n",
      "3, 000 3,000\n",
      "approximately 3, 850, 000 exajoules ( ej ) per year approximately 3,850,000 exajoules (ej) per year\n",
      "approximately 3, 000 ej per year approximately 3,000 ej per year\n",
      "a u. s. inventor, engineer and solar energy pioneer a u.s. inventor, engineer and solar energy pioneer\n",
      "22, 000 22,000\n",
      "60 to 70 % of the domestic hot water 60 to 70% of the domestic hot water\n",
      "over 90 % over 90%\n",
      "30 % ( 4. 65 ej / yr ) 30% (4.65 ej/yr)\n",
      "50 % ( 10. 1 ej / yr ) 50% (10.1 ej/yr)\n",
      "1 / 3 to 1 / 2 1/3 to 1/2\n",
      "90 – 150 °c ( 194 – 302 °f ) 90–150 °c (194–302 °f)\n",
      "solar total energy project ( step ) in shenandoah, georgia, usa solar total energy project (step) in shenandoah, georgia, usa\n",
      "perforated sun - facing walls used for preheating ventilation air perforated sun-facing walls used for preheating ventilation air\n",
      "16th - century arab alchemists 16th-century arab alchemists\n",
      "22, 700 l ( 5, 000 imp gal ; 6, 000 us gal ) per day 22,700 l (5,000 imp gal; 6,000 us gal) per day\n",
      "single - slope single-slope\n",
      "well - lit spaces that stay in a comfortable temperature range well-lit spaces that stay in a comfortable temperature range\n",
      "socrates'megaron house socrates' megaron house\n"
     ]
    }
   ],
   "source": [
    "\n",
    "question=\"who r u\"\n",
    "context=\"i lives in kanpur, i am adarsh\"\n",
    "# answer_start=context.index(\"i am adarsh\")\n",
    "answer=\"i\"\n",
    "# print(\"answer start indes:\", answer_start)\n",
    "\n",
    "def prep(data):\n",
    "    question=data[\"question\"]\n",
    "    context=data[\"context\"]\n",
    "    answer=data[\"answers\"][\"text\"][0]\n",
    "\n",
    "    tk=tokenizer(question,context,return_attention_mask=True,return_token_type_ids=True, max_length=512,truncation=\"only_second\")\n",
    "    tk[\"start_positions\"] = []\n",
    "    tk[\"end_positions\"]=[]\n",
    "    tk[\"check\"]=\"\"\n",
    "    try:\n",
    "        one_start=tk[\"token_type_ids\"].index(1)\n",
    "        # print(\"one index will start from this no:\" ,one_start)\n",
    "        context_ids=tk[\"input_ids\"][one_start:-1]\n",
    "        answer_ids=tokenizer(answer,return_attention_mask=False,return_token_type_ids=True)[\"input_ids\"][1:-1]\n",
    "        status=True\n",
    "        start=0\n",
    "        while start < len(context_ids)-len(answer_ids)+1:\n",
    "            # print(context_ids[start:start+len(answer_ids)])\n",
    "            if context_ids[start:start+len(answer_ids)]==answer_ids:\n",
    "                # print(\"find\", start)\n",
    "                status=False\n",
    "                break\n",
    "            else:\n",
    "                start+=1\n",
    "        if status:\n",
    "            tk[\"start_positions\"].append(0)\n",
    "            tk[\"end_positions\"].append(0)\n",
    "            return tk\n",
    "        if not status:\n",
    "            # print(tk[\"input_ids\"][one_start+start:one_start+start+len(answer_ids)], tokenizer.decode(tk[\"input_ids\"][one_start+start:one_start+start+len(answer_ids)]))\n",
    "            tk[\"start_positions\"].append(start+1)\n",
    "            tk[\"end_positions\"].append(start+len(answer_ids)+1)\n",
    "            tk[\"check\"]=tokenizer.decode(tk[\"input_ids\"][one_start+tk[\"start_positions\"][0]-1:one_start+tk[\"end_positions\"][0]-1])\n",
    "            return tk\n",
    "    except Exception as e:\n",
    "        # print(\"error:\",e)\n",
    "        tk[\"start_positions\"].append(0)\n",
    "        tk[\"end_positions\"].append(0)\n",
    "        return tk\n",
    "    \n",
    "\n",
    "# prep(dataset_train[0])\n",
    "dataset_train_new=dataset_train.map(prep)\n",
    "dataset_val_new=dataset_val.map(prep)\n",
    "print(\"\\n\",\"wrong preprocessing and respective samples\")\n",
    "\n",
    "def val(dataset_train_new):\n",
    "    for i in range(dataset_train_new.shape[0]):\n",
    "        if not dataset_train_new[i][\"check\"]==dataset_train_new[i][\"answers\"][\"text\"][0].lower():\n",
    "            print(dataset_train_new[i][\"check\"],dataset_train_new[i][\"answers\"][\"text\"][0].lower())\n",
    "    pass\n",
    "print(\"val :---------------------------------------------   \")\n",
    "val(dataset_val_new)\n",
    "print(\"train--------------------------------------------\")\n",
    "val(dataset_train_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 112\n",
      "2007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'text': ['2007'], 'answer_start': [550]}, '2007')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=437\n",
    "start=dataset_train_new[i][\"start_positions\"][0]\n",
    "end=dataset_train_new[i][\"end_positions\"][0]\n",
    "print(start,end)\n",
    "print(tokenizer.decode(tokenizer(dataset_train_new[i][\"context\"])[\"input_ids\"][start:end]))\n",
    "dataset_train_new[i][\"answers\"],dataset_train_new[i][\"check\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token inouts:  {'input_ids': tensor([[ 101, 2054, 2003, 1996, 3007, 1997, 2605, 1029,  102, 1996, 3007, 1997,\n",
      "         2605, 2003, 3000, 1012,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "start logits\n",
      " tensor([[ 0.2639, -0.2757, -0.0594, -0.0652, -0.1580, -0.0274, -0.0988, -0.3158,\n",
      "         -0.1541, -0.0853, -0.2042, -0.0613, -0.0793,  0.0651, -0.1710, -0.3175,\n",
      "         -0.1541]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] what is the capital of france? [SEP] the capital of france is'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_model=model\n",
    "original_model.eval()\n",
    "# Example context and question\n",
    "context = \"The  capital of France is Paris.\"\n",
    "question = \"What is the capital of France?\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(question, context, return_tensors='pt')\n",
    "print(\"token inouts: \", inputs)\n",
    "\n",
    "# Get the model's predictions\n",
    "with torch.no_grad():\n",
    "    outputs = original_model(**inputs)\n",
    "    # print(\"\\nmodel output \",outputs)\n",
    "    # it will score from context  \n",
    "    start_logits = outputs.start_logits\n",
    "    end_logits = outputs.end_logits\n",
    "\n",
    "print(\"start logits\\n\",start_logits)\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "start_index=torch.argmax(F.softmax(start_logits,dim=-1))\n",
    "end_index=torch.argmax(F.softmax(end_logits,dim=-1))\n",
    "input_part=inputs[\"input_ids\"][0][start_index:end_index]\n",
    "tokenizer.decode(input_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [09:13<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.666, 'grad_norm': 4.913923263549805, 'learning_rate': 1.9893333333333335e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [10:25<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.7142, 'grad_norm': 5.785029888153076, 'learning_rate': 1.9786666666666668e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [11:23<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.6162, 'grad_norm': 6.487402439117432, 'learning_rate': 1.968e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [12:30<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.8319, 'grad_norm': 6.562624931335449, 'learning_rate': 1.9573333333333335e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [13:35<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.8289, 'grad_norm': 6.349644660949707, 'learning_rate': 1.9466666666666668e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [14:40<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.0574, 'grad_norm': 6.799848556518555, 'learning_rate': 1.936e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [15:41<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.985, 'grad_norm': 6.271812915802002, 'learning_rate': 1.9253333333333334e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [16:43<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.9297, 'grad_norm': 6.279285907745361, 'learning_rate': 1.9146666666666667e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [17:45<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.0661, 'grad_norm': 7.903749465942383, 'learning_rate': 1.904e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [18:43<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.0131, 'grad_norm': 8.041516304016113, 'learning_rate': 1.8933333333333334e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [19:45<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.9831, 'grad_norm': 7.146139621734619, 'learning_rate': 1.8826666666666667e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [20:42<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.9103, 'grad_norm': 7.134524822235107, 'learning_rate': 1.8720000000000004e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [21:39<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.0409, 'grad_norm': 7.08110237121582, 'learning_rate': 1.8613333333333334e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [22:38<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.9635, 'grad_norm': 7.271071434020996, 'learning_rate': 1.8506666666666667e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [23:33<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.8896, 'grad_norm': 7.137335777282715, 'learning_rate': 1.8400000000000003e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [24:26<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.8839, 'grad_norm': 7.359590530395508, 'learning_rate': 1.8293333333333333e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [25:21<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.9644, 'grad_norm': 7.562987327575684, 'learning_rate': 1.8186666666666666e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [26:20<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.0493, 'grad_norm': 7.3899102210998535, 'learning_rate': 1.8080000000000003e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [27:21<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.9806, 'grad_norm': 8.710412979125977, 'learning_rate': 1.7973333333333333e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [28:12<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.7777, 'grad_norm': 7.693674087524414, 'learning_rate': 1.7866666666666666e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [29:09<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.8804, 'grad_norm': 7.7944440841674805, 'learning_rate': 1.7760000000000003e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [30:04<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.7878, 'grad_norm': 12.758084297180176, 'learning_rate': 1.7653333333333336e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [31:01<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.6966, 'grad_norm': 19.00139808654785, 'learning_rate': 1.7546666666666666e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [31:59<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.7791, 'grad_norm': 11.695365905761719, 'learning_rate': 1.7440000000000002e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [32:56<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.7151, 'grad_norm': 16.729888916015625, 'learning_rate': 1.7333333333333336e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [33:53<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.702, 'grad_norm': 20.921348571777344, 'learning_rate': 1.7226666666666665e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [34:48<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.5187, 'grad_norm': 15.49132251739502, 'learning_rate': 1.7120000000000002e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [35:48<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.5362, 'grad_norm': 16.419212341308594, 'learning_rate': 1.7013333333333335e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [36:41<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.625, 'grad_norm': 12.028736114501953, 'learning_rate': 1.690666666666667e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [37:35<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.5799, 'grad_norm': 18.143808364868164, 'learning_rate': 1.6800000000000002e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [38:28<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.5776, 'grad_norm': 15.114255905151367, 'learning_rate': 1.6693333333333335e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [39:25<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.5827, 'grad_norm': 11.787681579589844, 'learning_rate': 1.6586666666666668e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [40:20<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4955, 'grad_norm': 22.82002067565918, 'learning_rate': 1.648e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [41:13<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.5546, 'grad_norm': 18.725656509399414, 'learning_rate': 1.6373333333333335e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [42:09<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.356, 'grad_norm': 12.646859169006348, 'learning_rate': 1.6266666666666668e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [43:00<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.2988, 'grad_norm': 16.768985748291016, 'learning_rate': 1.616e-05, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [43:49<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.2773, 'grad_norm': 19.085947036743164, 'learning_rate': 1.6053333333333334e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [44:46<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.7437, 'grad_norm': 19.9232177734375, 'learning_rate': 1.5946666666666668e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [45:45<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.251, 'grad_norm': 12.825321197509766, 'learning_rate': 1.584e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [46:40<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.506, 'grad_norm': 17.77813720703125, 'learning_rate': 1.5733333333333334e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [47:33<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4723, 'grad_norm': 20.584077835083008, 'learning_rate': 1.5626666666666667e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [48:27<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3959, 'grad_norm': 14.242157936096191, 'learning_rate': 1.552e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [49:29<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.5165, 'grad_norm': 16.257322311401367, 'learning_rate': 1.5413333333333337e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [50:33<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4622, 'grad_norm': 20.737058639526367, 'learning_rate': 1.5306666666666667e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [51:33<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3778, 'grad_norm': 17.380245208740234, 'learning_rate': 1.5200000000000002e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [52:31<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.5213, 'grad_norm': 14.331584930419922, 'learning_rate': 1.5093333333333335e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [53:26<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.258, 'grad_norm': 18.51664924621582, 'learning_rate': 1.4986666666666667e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [54:24<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3702, 'grad_norm': 20.838098526000977, 'learning_rate': 1.4880000000000002e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [55:17<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.5695, 'grad_norm': 16.79546546936035, 'learning_rate': 1.4773333333333335e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [56:08<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.2022, 'grad_norm': 12.150315284729004, 'learning_rate': 1.4666666666666666e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [57:43<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.2873, 'grad_norm': 10.318766593933105, 'learning_rate': 1.4560000000000001e-05, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [58:52<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3903, 'grad_norm': 14.282320022583008, 'learning_rate': 1.4453333333333334e-05, 'epoch': 0.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [59:56<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.2784, 'grad_norm': 16.204599380493164, 'learning_rate': 1.434666666666667e-05, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 52/1875 [1:00:55<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3848, 'grad_norm': 18.72270965576172, 'learning_rate': 1.4240000000000001e-05, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:01:52<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1468, 'grad_norm': 16.839324951171875, 'learning_rate': 1.4133333333333334e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:02:49<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.369, 'grad_norm': 16.48255729675293, 'learning_rate': 1.4026666666666669e-05, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:03:45<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1716, 'grad_norm': 16.627744674682617, 'learning_rate': 1.392e-05, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:04:44<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4211, 'grad_norm': 27.214176177978516, 'learning_rate': 1.3813333333333334e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:05:39<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.375, 'grad_norm': 18.501312255859375, 'learning_rate': 1.3706666666666669e-05, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:06:44<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4184, 'grad_norm': 17.823911666870117, 'learning_rate': 1.3600000000000002e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:08:00<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4627, 'grad_norm': 14.916041374206543, 'learning_rate': 1.3493333333333333e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:09:00<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3215, 'grad_norm': 19.84585189819336, 'learning_rate': 1.3386666666666668e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                     \n",
      "\u001b[A                                                   \n",
      "\n",
      "  3%|▎         | 52/1875 [1:13:07<3:02:18,  6.00s/it]\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.264003753662109, 'eval_runtime': 215.5271, 'eval_samples_per_second': 4.64, 'eval_steps_per_second': 4.64, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:13:38<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1534, 'grad_norm': 15.678187370300293, 'learning_rate': 1.3280000000000002e-05, 'epoch': 1.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:14:36<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.095, 'grad_norm': 17.283498764038086, 'learning_rate': 1.3173333333333333e-05, 'epoch': 1.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:15:45<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0979, 'grad_norm': 15.33316421508789, 'learning_rate': 1.3066666666666668e-05, 'epoch': 1.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:16:47<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3065, 'grad_norm': 31.108409881591797, 'learning_rate': 1.2960000000000001e-05, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:17:50<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9091, 'grad_norm': 13.38608455657959, 'learning_rate': 1.2853333333333336e-05, 'epoch': 1.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:18:50<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1768, 'grad_norm': 16.51882553100586, 'learning_rate': 1.2746666666666668e-05, 'epoch': 1.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:19:48<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0972, 'grad_norm': 25.214786529541016, 'learning_rate': 1.2640000000000001e-05, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:20:45<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0063, 'grad_norm': 19.434467315673828, 'learning_rate': 1.2533333333333336e-05, 'epoch': 1.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:22:06<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.061, 'grad_norm': 29.911998748779297, 'learning_rate': 1.2426666666666667e-05, 'epoch': 1.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:23:04<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9133, 'grad_norm': 18.952817916870117, 'learning_rate': 1.232e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:24:02<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8827, 'grad_norm': 16.65705680847168, 'learning_rate': 1.2213333333333336e-05, 'epoch': 1.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:25:18<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0103, 'grad_norm': 19.001529693603516, 'learning_rate': 1.2106666666666667e-05, 'epoch': 1.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:26:14<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9266, 'grad_norm': 15.141953468322754, 'learning_rate': 1.2e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:27:09<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0271, 'grad_norm': 16.037574768066406, 'learning_rate': 1.1893333333333335e-05, 'epoch': 1.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:28:15<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0431, 'grad_norm': 18.01975440979004, 'learning_rate': 1.1786666666666668e-05, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:29:12<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1237, 'grad_norm': 33.61321258544922, 'learning_rate': 1.168e-05, 'epoch': 1.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:30:13<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9984, 'grad_norm': 13.269518852233887, 'learning_rate': 1.1573333333333335e-05, 'epoch': 1.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:31:12<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0631, 'grad_norm': 26.360780715942383, 'learning_rate': 1.1466666666666668e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:32:27<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1639, 'grad_norm': 11.62990951538086, 'learning_rate': 1.136e-05, 'epoch': 1.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:33:26<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.981, 'grad_norm': 16.59285545349121, 'learning_rate': 1.1253333333333335e-05, 'epoch': 1.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:34:21<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0817, 'grad_norm': 28.402807235717773, 'learning_rate': 1.1146666666666668e-05, 'epoch': 1.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:35:16<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8694, 'grad_norm': 14.84489631652832, 'learning_rate': 1.1040000000000001e-05, 'epoch': 1.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:36:16<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9049, 'grad_norm': 20.08873748779297, 'learning_rate': 1.0933333333333334e-05, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:37:10<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.912, 'grad_norm': 16.3509464263916, 'learning_rate': 1.0826666666666667e-05, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:38:09<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.109, 'grad_norm': 21.144804000854492, 'learning_rate': 1.072e-05, 'epoch': 1.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:39:08<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1077, 'grad_norm': 14.221338272094727, 'learning_rate': 1.0613333333333334e-05, 'epoch': 1.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:40:14<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0637, 'grad_norm': 22.215511322021484, 'learning_rate': 1.0506666666666667e-05, 'epoch': 1.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:41:07<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.818, 'grad_norm': 20.80096435546875, 'learning_rate': 1.04e-05, 'epoch': 1.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:42:03<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8116, 'grad_norm': 29.08956527709961, 'learning_rate': 1.0293333333333335e-05, 'epoch': 1.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:42:59<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1034, 'grad_norm': 18.360048294067383, 'learning_rate': 1.0186666666666667e-05, 'epoch': 1.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:43:58<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0673, 'grad_norm': 16.808866500854492, 'learning_rate': 1.008e-05, 'epoch': 1.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:44:56<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8919, 'grad_norm': 25.894018173217773, 'learning_rate': 9.973333333333333e-06, 'epoch': 1.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:45:58<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8296, 'grad_norm': 23.948936462402344, 'learning_rate': 9.866666666666668e-06, 'epoch': 1.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:46:50<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0433, 'grad_norm': 16.354461669921875, 'learning_rate': 9.760000000000001e-06, 'epoch': 1.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:47:47<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.865, 'grad_norm': 20.213594436645508, 'learning_rate': 9.653333333333335e-06, 'epoch': 1.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:48:41<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9126, 'grad_norm': 22.043359756469727, 'learning_rate': 9.546666666666668e-06, 'epoch': 1.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:49:44<3:02:18,  6.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0519, 'grad_norm': 16.45553970336914, 'learning_rate': 9.440000000000001e-06, 'epoch': 1.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:50:37<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0342, 'grad_norm': 20.34028434753418, 'learning_rate': 9.333333333333334e-06, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:51:51<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9657, 'grad_norm': 16.727689743041992, 'learning_rate': 9.226666666666668e-06, 'epoch': 1.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:52:45<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9393, 'grad_norm': 20.440753936767578, 'learning_rate': 9.12e-06, 'epoch': 1.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:53:36<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0063, 'grad_norm': 20.991039276123047, 'learning_rate': 9.013333333333334e-06, 'epoch': 1.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:54:29<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0121, 'grad_norm': 18.16082191467285, 'learning_rate': 8.906666666666667e-06, 'epoch': 1.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:55:22<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9232, 'grad_norm': 21.308801651000977, 'learning_rate': 8.8e-06, 'epoch': 1.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:56:17<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1403, 'grad_norm': 31.579111099243164, 'learning_rate': 8.693333333333334e-06, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:57:17<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0997, 'grad_norm': 21.338041305541992, 'learning_rate': 8.586666666666667e-06, 'epoch': 1.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:58:13<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8402, 'grad_norm': 24.577877044677734, 'learning_rate': 8.48e-06, 'epoch': 1.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:59:05<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7881, 'grad_norm': 30.21662712097168, 'learning_rate': 8.373333333333335e-06, 'epoch': 1.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [1:59:57<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0215, 'grad_norm': 19.18082618713379, 'learning_rate': 8.266666666666667e-06, 'epoch': 1.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:00:49<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9168, 'grad_norm': 20.926498413085938, 'learning_rate': 8.16e-06, 'epoch': 1.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:01:45<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9999, 'grad_norm': 14.256654739379883, 'learning_rate': 8.053333333333335e-06, 'epoch': 1.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:02:42<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9348, 'grad_norm': 30.200977325439453, 'learning_rate': 7.946666666666666e-06, 'epoch': 1.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:03:36<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3477, 'grad_norm': 24.105684280395508, 'learning_rate': 7.840000000000001e-06, 'epoch': 1.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:04:30<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1587, 'grad_norm': 16.823246002197266, 'learning_rate': 7.733333333333334e-06, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:05:25<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8973, 'grad_norm': 21.1325626373291, 'learning_rate': 7.626666666666668e-06, 'epoch': 1.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:06:23<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8059, 'grad_norm': 23.340959548950195, 'learning_rate': 7.520000000000001e-06, 'epoch': 1.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:07:22<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8622, 'grad_norm': 26.840126037597656, 'learning_rate': 7.413333333333333e-06, 'epoch': 1.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:08:14<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.112, 'grad_norm': 28.169458389282227, 'learning_rate': 7.306666666666667e-06, 'epoch': 1.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:09:12<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9574, 'grad_norm': 26.650617599487305, 'learning_rate': 7.2000000000000005e-06, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:10:10<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9292, 'grad_norm': 20.885995864868164, 'learning_rate': 7.093333333333335e-06, 'epoch': 1.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:11:03<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8547, 'grad_norm': 15.64089584350586, 'learning_rate': 6.986666666666667e-06, 'epoch': 1.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:11:58<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1, 'grad_norm': 22.911314010620117, 'learning_rate': 6.88e-06, 'epoch': 1.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:12:55<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0902, 'grad_norm': 24.103330612182617, 'learning_rate': 6.773333333333334e-06, 'epoch': 1.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:13:49<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7927, 'grad_norm': 15.917845726013184, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                     \n",
      "\u001b[A                                                  \n",
      "\n",
      "  3%|▎         | 52/1875 [2:17:03<3:02:18,  6.00s/it]\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.164388656616211, 'eval_runtime': 194.1091, 'eval_samples_per_second': 5.152, 'eval_steps_per_second': 5.152, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:18:01<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8282, 'grad_norm': 19.174558639526367, 'learning_rate': 6.560000000000001e-06, 'epoch': 2.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:18:56<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5163, 'grad_norm': 19.516908645629883, 'learning_rate': 6.453333333333334e-06, 'epoch': 2.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:19:51<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7517, 'grad_norm': 29.182537078857422, 'learning_rate': 6.346666666666668e-06, 'epoch': 2.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:20:45<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8297, 'grad_norm': 31.258785247802734, 'learning_rate': 6.24e-06, 'epoch': 2.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:21:40<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6843, 'grad_norm': 34.20768356323242, 'learning_rate': 6.133333333333334e-06, 'epoch': 2.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:22:37<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7799, 'grad_norm': 29.580957412719727, 'learning_rate': 6.026666666666668e-06, 'epoch': 2.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:23:30<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.718, 'grad_norm': 21.777570724487305, 'learning_rate': 5.92e-06, 'epoch': 2.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:24:28<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5704, 'grad_norm': 24.351287841796875, 'learning_rate': 5.813333333333334e-06, 'epoch': 2.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:25:22<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.746, 'grad_norm': 28.265743255615234, 'learning_rate': 5.706666666666667e-06, 'epoch': 2.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:26:14<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6798, 'grad_norm': 26.848594665527344, 'learning_rate': 5.600000000000001e-06, 'epoch': 2.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:27:07<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8701, 'grad_norm': 20.632665634155273, 'learning_rate': 5.493333333333334e-06, 'epoch': 2.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:28:00<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6977, 'grad_norm': 18.81532859802246, 'learning_rate': 5.386666666666667e-06, 'epoch': 2.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:28:54<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6222, 'grad_norm': 17.635772705078125, 'learning_rate': 5.28e-06, 'epoch': 2.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:29:47<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6594, 'grad_norm': 19.2784423828125, 'learning_rate': 5.1733333333333335e-06, 'epoch': 2.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:30:41<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6836, 'grad_norm': 29.68105697631836, 'learning_rate': 5.0666666666666676e-06, 'epoch': 2.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:31:46<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7087, 'grad_norm': 30.475189208984375, 'learning_rate': 4.960000000000001e-06, 'epoch': 2.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:33:08<3:02:18,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6253, 'grad_norm': 26.899547576904297, 'learning_rate': 4.853333333333334e-06, 'epoch': 2.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:34:08<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6956, 'grad_norm': 31.28883934020996, 'learning_rate': 4.746666666666667e-06, 'epoch': 2.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:35:03<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8451, 'grad_norm': 28.453901290893555, 'learning_rate': 4.6400000000000005e-06, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:36:06<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8453, 'grad_norm': 31.709674835205078, 'learning_rate': 4.533333333333334e-06, 'epoch': 2.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:37:05<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7186, 'grad_norm': 25.33203887939453, 'learning_rate': 4.426666666666667e-06, 'epoch': 2.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:38:07<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5636, 'grad_norm': 16.533735275268555, 'learning_rate': 4.32e-06, 'epoch': 2.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:39:04<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5591, 'grad_norm': 20.372665405273438, 'learning_rate': 4.213333333333333e-06, 'epoch': 2.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:40:11<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7653, 'grad_norm': 17.25421714782715, 'learning_rate': 4.1066666666666674e-06, 'epoch': 2.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:41:09<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.665, 'grad_norm': 16.245962142944336, 'learning_rate': 4.000000000000001e-06, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:42:39<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.4351, 'grad_norm': 19.384082794189453, 'learning_rate': 3.893333333333333e-06, 'epoch': 2.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:43:36<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7379, 'grad_norm': 27.879798889160156, 'learning_rate': 3.7866666666666667e-06, 'epoch': 2.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:44:33<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6653, 'grad_norm': 21.285446166992188, 'learning_rate': 3.6800000000000003e-06, 'epoch': 2.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:45:32<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5137, 'grad_norm': 18.6859188079834, 'learning_rate': 3.5733333333333336e-06, 'epoch': 2.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:46:33<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5711, 'grad_norm': 18.204238891601562, 'learning_rate': 3.4666666666666672e-06, 'epoch': 2.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:47:30<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7332, 'grad_norm': 25.21444320678711, 'learning_rate': 3.3600000000000004e-06, 'epoch': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:48:26<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7542, 'grad_norm': 24.150562286376953, 'learning_rate': 3.2533333333333332e-06, 'epoch': 2.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:49:29<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7151, 'grad_norm': 26.1884765625, 'learning_rate': 3.146666666666667e-06, 'epoch': 2.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:50:36<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5717, 'grad_norm': 19.917835235595703, 'learning_rate': 3.04e-06, 'epoch': 2.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:51:37<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7759, 'grad_norm': 16.652088165283203, 'learning_rate': 2.9333333333333338e-06, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:52:33<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7821, 'grad_norm': 20.71863555908203, 'learning_rate': 2.826666666666667e-06, 'epoch': 2.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:53:26<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.651, 'grad_norm': 19.380531311035156, 'learning_rate': 2.7200000000000002e-06, 'epoch': 2.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:54:22<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8378, 'grad_norm': 20.3316593170166, 'learning_rate': 2.6133333333333334e-06, 'epoch': 2.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:55:18<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8923, 'grad_norm': 21.952529907226562, 'learning_rate': 2.5066666666666667e-06, 'epoch': 2.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:56:18<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6979, 'grad_norm': 20.25807762145996, 'learning_rate': 2.4000000000000003e-06, 'epoch': 2.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:57:10<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5547, 'grad_norm': 25.733854293823242, 'learning_rate': 2.2933333333333335e-06, 'epoch': 2.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:58:07<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6381, 'grad_norm': 17.276927947998047, 'learning_rate': 2.1866666666666668e-06, 'epoch': 2.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [2:59:04<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8139, 'grad_norm': 18.61054229736328, 'learning_rate': 2.08e-06, 'epoch': 2.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [3:00:03<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.528, 'grad_norm': 25.804948806762695, 'learning_rate': 1.9733333333333336e-06, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [3:01:03<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6785, 'grad_norm': 29.210485458374023, 'learning_rate': 1.8666666666666669e-06, 'epoch': 2.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [3:02:02<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5733, 'grad_norm': 30.382080078125, 'learning_rate': 1.76e-06, 'epoch': 2.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [3:03:00<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6313, 'grad_norm': 18.174705505371094, 'learning_rate': 1.6533333333333335e-06, 'epoch': 2.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [3:03:53<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.667, 'grad_norm': 22.26542091369629, 'learning_rate': 1.546666666666667e-06, 'epoch': 2.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [3:04:47<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6547, 'grad_norm': 26.900564193725586, 'learning_rate': 1.44e-06, 'epoch': 2.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [3:05:40<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7281, 'grad_norm': 31.811599731445312, 'learning_rate': 1.3333333333333334e-06, 'epoch': 2.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [3:06:33<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5672, 'grad_norm': 18.1115665435791, 'learning_rate': 1.2266666666666666e-06, 'epoch': 2.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [3:07:26<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5858, 'grad_norm': 24.51546287536621, 'learning_rate': 1.12e-06, 'epoch': 2.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [3:08:32<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.4531, 'grad_norm': 20.316272735595703, 'learning_rate': 1.0133333333333333e-06, 'epoch': 2.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [3:09:37<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6169, 'grad_norm': 22.166837692260742, 'learning_rate': 9.066666666666668e-07, 'epoch': 2.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [3:10:43<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7275, 'grad_norm': 34.577117919921875, 'learning_rate': 8.000000000000001e-07, 'epoch': 2.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [3:11:49<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6238, 'grad_norm': 20.786624908447266, 'learning_rate': 6.933333333333334e-07, 'epoch': 2.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [3:12:59<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6056, 'grad_norm': 21.785205841064453, 'learning_rate': 5.866666666666667e-07, 'epoch': 2.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [3:14:00<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8088, 'grad_norm': 30.349674224853516, 'learning_rate': 4.800000000000001e-07, 'epoch': 2.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [3:15:03<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6811, 'grad_norm': 33.60478210449219, 'learning_rate': 3.733333333333334e-07, 'epoch': 2.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [3:16:09<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.4551, 'grad_norm': 15.598569869995117, 'learning_rate': 2.666666666666667e-07, 'epoch': 2.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [3:17:16<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5296, 'grad_norm': 14.22250747680664, 'learning_rate': 1.6e-07, 'epoch': 2.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 52/1875 [3:18:27<3:02:18,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8063, 'grad_norm': 15.695228576660156, 'learning_rate': 5.3333333333333334e-08, 'epoch': 2.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                     \n",
      "\u001b[A                                                  \n",
      "\n",
      "  3%|▎         | 52/1875 [3:23:17<3:02:18,  6.00s/it]\n",
      "\u001b[A\n",
      "                                                     \n",
      "100%|██████████| 1875/1875 [3:15:32<00:00,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.193178653717041, 'eval_runtime': 245.1866, 'eval_samples_per_second': 4.079, 'eval_steps_per_second': 4.079, 'epoch': 3.0}\n",
      "{'train_runtime': 11732.2718, 'train_samples_per_second': 1.279, 'train_steps_per_second': 0.16, 'train_loss': 4.0935096801757815, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1875, training_loss=4.0935096801757815, metrics={'train_runtime': 11732.2718, 'train_samples_per_second': 1.279, 'train_steps_per_second': 0.16, 'total_flos': 670187628432504.0, 'train_loss': 4.0935096801757815, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparation for fine tuning\n",
    "\n",
    "# epochs: no of times a dataset voisited\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_dailog_sum\", # trained model will be saved\n",
    "    eval_strategy=\"epoch\",  # at end of every epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,  # Reduce batch size for CPU\n",
    "    per_device_eval_batch_size=1,   # Reduce batch size for CPU\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,  # regularization technique\n",
    "    gradient_accumulation_steps=8,  # Accumulate gradients to simulate larger batch size\n",
    "    logging_dir='./logs_dailog_sum_test',\n",
    "    logging_steps=10)\n",
    "\n",
    "# Data collator that will dynamically pad the inputs received\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# tokenizer: text-> token-> add_special_tokens -> to_numerical\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train_new,\n",
    "    eval_dataset=dataset_val_new,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    "    )\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model type:  <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForQuestionAnswering'>\n",
      "question:  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? \n",
      "answer:  Saint Bernadette Soubirous\n",
      "original_model: tensor(99) tensor(78)\n",
      "new_pred: tensor(99) tensor(78)\n"
     ]
    }
   ],
   "source": [
    "path=r\"C:\\Users\\adarsh.a.kumar.gupta\\OneDrive - Accenture\\Desktop\\accenture\\rag\\results_dailog_sum\\checkpoint-18/\"\n",
    "model_tuned= AutoModelForQuestionAnswering.from_pretrained(path)\n",
    "print(\"model type: \",type(model_tuned))\n",
    "token_tuned=AutoTokenizer.from_pretrained(path)\n",
    "i=0\n",
    "q=dataset_train_new[i][\"question\"]\n",
    "c=dataset_train_new[i][\"context\"]\n",
    "a=dataset_train_new[i][\"answers\"][\"text\"][0]\n",
    "print(\"question: \",q,\"\\nanswer: \",a)\n",
    "\n",
    "\n",
    "def pred_():\n",
    "    old_pred=model(**tokenizer(q,c, return_tensors=\"pt\"))\n",
    "    start=torch.argmax(old_pred[\"start_logits\"][0])\n",
    "    end=torch.argmax(old_pred[\"end_logits\"][0])\n",
    "\n",
    "    new_pred=model_tuned(**token_tuned(q,c,return_tensors=\"pt\"))\n",
    "    start=torch.argmax(new_pred[\"start_logits\"][0])\n",
    "    end=torch.argmax(new_pred[\"end_logits\"][0])\n",
    "    print(\"original_model:\",start, end)\n",
    "    print(\"new_pred:\",start, end)\n",
    "    pass\n",
    "pred_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 17)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=len([ 0.1112, -0.1654,  0.0341, -0.0568,  0.0723,  0.1150,  0.0166, -0.0619,\n",
    "          0.1898,  0.1546,  0.1931,  0.1557,  0.0568,  0.0662,  0.0169, -0.1304,\n",
    "         -0.2991])\n",
    "\n",
    "b=len(tokenizer(q)[\"input_ids\"])\n",
    "a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# casual lm: gpt2, gpt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "# ! pip install peft\n",
    "# ! pip install transformers datasets torch\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# Specify the dataset name and the column containing the content\n",
    "token=\"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\"\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    GenerationConfig\n",
    ")\n",
    "\n",
    "# bits and byte config need gpu to access it\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#    load_in_4bit=True,\n",
    "#    bnb_4bit_quant_type=\"nf4\",\n",
    "#    bnb_4bit_use_double_quant=True,\n",
    "#    bnb_4bit_compute_dtype=torch.bfloat16\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since squad couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at C:\\Users\\adarsh.a.kumar.gupta\\.cache\\huggingface\\datasets\\squad\\plain_text\\0.0.0\\7b6d24c440a36b6815f21b70d25016731768db1f (last modified on Tue Sep  3 13:17:18 2024).\n",
      "Using the latest cached version of the dataset since squad couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at C:\\Users\\adarsh.a.kumar.gupta\\.cache\\huggingface\\datasets\\squad\\plain_text\\0.0.0\\7b6d24c440a36b6815f21b70d25016731768db1f (last modified on Tue Sep  3 13:17:18 2024).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '56be4db0acb8001400a502ec', 'title': 'Super_Bowl_50', 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.', 'question': 'Which NFL team represented the AFC at Super Bowl 50?', 'answers': {'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'], 'answer_start': [177, 177, 177]}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_dataset_name = \"squad\"\n",
    "dataset_train = load_dataset(huggingface_dataset_name,split=\"train[:500]\")\n",
    "dataset_val= load_dataset(huggingface_dataset_name,split=\"validation[:100]\")\n",
    "print(dataset_val[0])\n",
    "dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLS token: [CLS]\n",
      "SEP token: [SEP]\n",
      "PAD token: [PAD]\n",
      "UNK token: [UNK]\n",
      "MASK token: [MASK]\n",
      "eos token: [EOS]\n",
      "pad token: [PAD]\n",
      "CLS token ID: 101\n",
      "SEP token ID: 102\n",
      "PAD token ID: 0\n",
      "UNK token ID: 100\n",
      "MASK token ID: 103\n",
      "eos token: 30522\n",
      "pad token: 0\n",
      "right\n"
     ]
    }
   ],
   "source": [
    "model_name='microsoft/phi-2'\n",
    "model_name1=\"distilbert/distilbert-base-uncased\"\n",
    "original_model = AutoModelForMaskedLM.from_pretrained(model_name1);\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name1,add_eos_token=True,add_bos_token=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(model_name1, add_bos_token=True, trust_remote_code=True, use_fast=False)\n",
    "special_tokens_dict = {'eos_token': '[EOS]', 'pad_token': '[PAD]'}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "# bert not use eos token\n",
    "# Check special tokens\n",
    "print(\"CLS token:\", tokenizer.cls_token)\n",
    "print(\"SEP token:\", tokenizer.sep_token)\n",
    "print(\"PAD token:\", tokenizer.pad_token)\n",
    "print(\"UNK token:\", tokenizer.unk_token)\n",
    "print(\"MASK token:\", tokenizer.mask_token)\n",
    "print(\"eos token:\", tokenizer.eos_token)\n",
    "print(\"pad token:\", tokenizer.pad_token)\n",
    "\n",
    "# Check special token IDs\n",
    "print(\"CLS token ID:\", tokenizer.cls_token_id)\n",
    "print(\"SEP token ID:\", tokenizer.sep_token_id)\n",
    "print(\"PAD token ID:\", tokenizer.pad_token_id)\n",
    "print(\"UNK token ID:\", tokenizer.unk_token_id)\n",
    "print(\"MASK token ID:\", tokenizer.mask_token_id)\n",
    "print(\"eos token:\", tokenizer.eos_token_id)\n",
    "print(\"pad token:\", tokenizer.pad_token_id)\n",
    "\n",
    "print(tokenizer.padding_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import Trainer\n",
    "from transformers import DataCollatorWithPadding  # each batch have same input length\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# Specify the dataset name and the column containing the content\n",
    "token=\"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "#model have difference between lowrr case and upper case\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.bert.modeling_bert.BertForSequenceClassification"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 178, 182, 8050, 7666, 1324, 102, 178, 182, 8050, 7666, 1324, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1=\"i m adarsh\"\n",
    "tokenizer(e1,e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.bert.modeling_bert.BertForSequenceClassification"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[0.7374, 0.1463]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m out\u001b[38;5;241m=\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtoken)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(out)\n\u001b[1;32m----> 5\u001b[0m pred_cat\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39margmax(out\u001b[38;5;241m.\u001b[39mlogits)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred cat:\u001b[39m\u001b[38;5;124m\"\u001b[39m,pred_cat)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "txt=\"hi i m adarsh\"\n",
    "token=tokenizer(txt,return_tensors=\"pt\")\n",
    "out=model(**token)\n",
    "print(out)\n",
    "pred_cat=torch.argmax(out.logits).item()\n",
    "print(\"pred cat:\",pred_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at C:\\Users\\adarsh.a.kumar.gupta\\.cache\\huggingface\\datasets\\imdb\\plain_text\\0.0.0\\e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Fri Sep 13 13:22:56 2024).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"imdb\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_datasets[\"train\"][0]    {'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "print('raw_datasets[\"train\"][0]   ',raw_datasets[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 25000/25000 [00:16<00:00, 1549.92 examples/s]\n",
      "Map: 100%|██████████| 25000/25000 [00:17<00:00, 1425.63 examples/s]\n",
      "Map: 100%|██████████| 50000/50000 [00:36<00:00, 1366.27 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    # print(\"-----\",examples.keys())\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(100)) \n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(100)) \n",
    "full_train_dataset = tokenized_datasets[\"train\"]\n",
    "full_eval_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[0.6581, 0.1996]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=tokenizer(raw_datasets[\"train\"][0][\"text\"], padding=\"max_length\", return_tensors=\"pt\",truncation=True)\n",
    "# print(a)\n",
    "model.eval()\n",
    "model(**a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 10/36 [05:54<15:30, 35.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7128, 'grad_norm': 2.7498416900634766, 'learning_rate': 1.4444444444444446e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 12/36 [07:05<14:14, 35.59s/it]\n",
      " 33%|███▎      | 12/36 [10:46<14:14, 35.59s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6764088273048401, 'eval_runtime': 202.8652, 'eval_samples_per_second': 0.493, 'eval_steps_per_second': 0.493, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 20/36 [15:13<10:49, 40.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6425, 'grad_norm': 3.4859063625335693, 'learning_rate': 8.888888888888888e-06, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 25/36 [18:04<06:31, 35.58s/it]\n",
      " 69%|██████▉   | 25/36 [21:25<06:31, 35.58s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6494042277336121, 'eval_runtime': 201.0355, 'eval_samples_per_second': 0.497, 'eval_steps_per_second': 0.497, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 30/36 [24:23<04:58, 49.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5993, 'grad_norm': 6.063984394073486, 'learning_rate': 3.3333333333333333e-06, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      "100%|██████████| 36/36 [32:25<00:00, 54.05s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6519677042961121, 'eval_runtime': 260.1033, 'eval_samples_per_second': 0.384, 'eval_steps_per_second': 0.384, 'epoch': 2.88}\n",
      "{'train_runtime': 1945.8785, 'train_samples_per_second': 0.154, 'train_steps_per_second': 0.019, 'train_loss': 0.6330972048971388, 'epoch': 2.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=36, training_loss=0.6330972048971388, metrics={'train_runtime': 1945.8785, 'train_samples_per_second': 0.154, 'train_steps_per_second': 0.019, 'total_flos': 75775983943680.0, 'train_loss': 0.6330972048971388, 'epoch': 2.88})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparation for fine tuning\n",
    "# epochs: no of times a dataset voisited\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\", # trained model will be saved\n",
    "    eval_strategy=\"epoch\", # eval model at every stop or every epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,  # Reduce batch size for CPU, its batch size use for traing \n",
    "    per_device_eval_batch_size=1,   # Reduce batch size for CPU\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,  # regularization technique\n",
    "    gradient_accumulation_steps=8,  # Accumulate gradients to simulate larger batch size\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10)\n",
    "\n",
    "\n",
    "# Data collator that will dynamically pad the inputs received\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# tokenizer: text-> token-> add_special_tokens -> to_numerical\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    "    )\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:04<00:00,  1.85s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6519677042961121,\n",
       " 'eval_model_preparation_time': 0.0058,\n",
       " 'eval_accuracy': 0.64,\n",
       " 'eval_runtime': 186.1044,\n",
       " 'eval_samples_per_second': 0.537,\n",
       " 'eval_steps_per_second': 0.537}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\" , trust_remote_code=True)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "path=r\"C:\\Users\\adarsh.a.kumar.gupta\\OneDrive - Accenture\\Desktop\\accenture\\rag\\results\\checkpoint-3\\/\"\n",
    "fine_model = AutoModelForSequenceClassification.from_pretrained(path)\n",
    "\n",
    "# Load the tokenizer\n",
    "fine_tokenizer = AutoTokenizer.from_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[0.6440, 0.3205]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "SequenceClassifierOutput(loss=None, logits=tensor([[0.5226, 0.4859]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "pred cat: 0\n"
     ]
    }
   ],
   "source": [
    "txt=\"hi i m adarsh\"\n",
    "fine_model_token=fine_tokenizer(txt,return_tensors=\"pt\")\n",
    "fine_model_out=fine_model(**fine_model_token)\n",
    "print(fine_model_out)\n",
    "\n",
    "actual_model=tokenizer(txt,return_tensors=\"pt\")\n",
    "actual_model_out=model(**actual_model)\n",
    "print(actual_model_out)\n",
    "\n",
    "pred_cat=torch.argmax(out.logits).item()\n",
    "print(\"pred cat:\",pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
